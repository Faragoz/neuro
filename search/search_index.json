{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NeuroRPC Documentation Welcome to the NeuroRPC project documentation. NeuroRPC is a Python-based framework that provides an interface for remote procedure calls (RPC) over TCP/IP in the context of distributed and embedded systems. The library has been specifically developed to facilitate communication between Python applications and the LabVIEW Actor Framework , enabling reproducible, modular, and low-latency control architectures for experimental platforms. Objectives The primary objectives of NeuroRPC are: To offer a transparent client\u2013server model for exchanging structured messages between heterogeneous environments (Python \u2194 LabVIEW). To enable the design of actor-based systems in which commands and data streams are handled as serializable messages. To support scientific instrumentation workflows , such as real-time data acquisition, signal analysis, and closed-loop experimental control. To provide a foundation that can be extended to other protocols or platforms while preserving consistency and interoperability. Key Features TCP-based communication layer ensuring reliable and ordered message delivery. Serialization/deserialization mechanisms compatible with LabVIEW binary flattening. Actor-oriented modularity , allowing processes to be encapsulated as autonomous units. Cross-platform support through Python and LabVIEW integration. Documentation auto-generation via MkDocs and mkdocstrings . Structure of This Documentation Conceptual Overview \u2013 background on the RPC model, actor-based design principles, and system architecture. API Reference \u2013 detailed technical specification of modules, classes, and methods. Examples and Workflows \u2013 application to data acquisition, remote control, and message handling. Integration Guidelines \u2013 recommendations for extending NeuroRPC within experimental or industrial frameworks. Quickstart Minimal client example ```bash from neuro_rpc import Client client = Client(\"127.0.0.1\", port=2001) client.rpc(\"Display Text\", {\"Message\": \"Trying something :)\", \"exec_time\": 0}, False)","title":"Home"},{"location":"#neurorpc-documentation","text":"Welcome to the NeuroRPC project documentation. NeuroRPC is a Python-based framework that provides an interface for remote procedure calls (RPC) over TCP/IP in the context of distributed and embedded systems. The library has been specifically developed to facilitate communication between Python applications and the LabVIEW Actor Framework , enabling reproducible, modular, and low-latency control architectures for experimental platforms.","title":"NeuroRPC Documentation"},{"location":"#objectives","text":"The primary objectives of NeuroRPC are: To offer a transparent client\u2013server model for exchanging structured messages between heterogeneous environments (Python \u2194 LabVIEW). To enable the design of actor-based systems in which commands and data streams are handled as serializable messages. To support scientific instrumentation workflows , such as real-time data acquisition, signal analysis, and closed-loop experimental control. To provide a foundation that can be extended to other protocols or platforms while preserving consistency and interoperability.","title":"Objectives"},{"location":"#key-features","text":"TCP-based communication layer ensuring reliable and ordered message delivery. Serialization/deserialization mechanisms compatible with LabVIEW binary flattening. Actor-oriented modularity , allowing processes to be encapsulated as autonomous units. Cross-platform support through Python and LabVIEW integration. Documentation auto-generation via MkDocs and mkdocstrings .","title":"Key Features"},{"location":"#structure-of-this-documentation","text":"Conceptual Overview \u2013 background on the RPC model, actor-based design principles, and system architecture. API Reference \u2013 detailed technical specification of modules, classes, and methods. Examples and Workflows \u2013 application to data acquisition, remote control, and message handling. Integration Guidelines \u2013 recommendations for extending NeuroRPC within experimental or industrial frameworks.","title":"Structure of This Documentation"},{"location":"#quickstart","text":"Minimal client example ```bash from neuro_rpc import Client client = Client(\"127.0.0.1\", port=2001) client.rpc(\"Display Text\", {\"Message\": \"Trying something :)\", \"exec_time\": 0}, False)","title":"Quickstart"},{"location":"reference/Benchmark/","text":"Client TCP client for framed JSON-RPC-like communication. This module implements a Python client that communicates with a LabVIEW/CompactRIO server using a custom framed JSON message protocol. It manages socket lifecycle, message serialization, connection retries, and integration with the RPC stack. Notes All socket operations are blocking. Background operation is achieved by running the client in a thread. Client(host='127.0.0.1', port=6363, encoding='UTF-8', endian='>I', timeout=10.0, max_retries=3, retry_delay=1.0, handler=None, no_delay=True) TCP Client for framed JSON messages. Manages connection lifecycle, sending/receiving messages, background thread execution, and integration with RPC handlers and trackers. Initialize a Client instance with connection parameters. Parameters: host ( str , default: '127.0.0.1' ) \u2013 Target hostname or IP address. port ( int , default: 6363 ) \u2013 TCP port of the server. encoding ( str , default: 'UTF-8' ) \u2013 Encoding for JSON messages. endian ( str , default: '>I' ) \u2013 Struct format for message length (e.g., '>I' big-endian). timeout ( float , default: 10.0 ) \u2013 Socket timeout in seconds. max_retries ( int , default: 3 ) \u2013 Maximum number of connection attempts. retry_delay ( float , default: 1.0 ) \u2013 Delay between retry attempts in seconds. handler \u2013 Optional RPC handler, defaults to RPCMethods() . no_delay ( bool , default: True ) \u2013 If True, disables Nagle\u2019s algorithm and sets DSCP EF. Source code in python/neuro_rpc/Client.py def __init__(self, host: str = \"127.0.0.1\", port: int = 6363, encoding: str = 'UTF-8', endian: str = '>I', timeout: float = 10.0, max_retries: int = 3, retry_delay: float = 1.0, handler=None, no_delay = True): \"\"\" Initialize a Client instance with connection parameters. Args: host (str): Target hostname or IP address. port (int): TCP port of the server. encoding (str): Encoding for JSON messages. endian (str): Struct format for message length (e.g., ``'>I'`` big-endian). timeout (float): Socket timeout in seconds. max_retries (int): Maximum number of connection attempts. retry_delay (float): Delay between retry attempts in seconds. handler: Optional RPC handler, defaults to ``RPCMethods()``. no_delay (bool): If True, disables Nagle\u2019s algorithm and sets DSCP EF. \"\"\" self.host = host self.port = port self.encoding = encoding self.endian = endian self.timeout = timeout self.max_retries = max_retries self.retry_delay = retry_delay self.no_delay = no_delay self.client = None self.client_thread = None self.connected = False self.thread_running = False self.logger = Logger.get_logger(self.__class__.__name__()) # Handling methods self.handler = RPCMethods() self.header_bytes = 4 self.trailer_bytes = 4 connect(retry=True) Establish a TCP connection with retry support. Parameters: retry ( bool , default: True ) \u2013 Whether to retry failed attempts. Returns: bool ( bool ) \u2013 True if connected successfully. Raises: ConnectionError \u2013 If all attempts fail. Source code in python/neuro_rpc/Client.py def connect(self, retry: bool = True) -> bool: \"\"\" Establish a TCP connection with retry support. Args: retry (bool): Whether to retry failed attempts. Returns: bool: True if connected successfully. Raises: ConnectionError: If all attempts fail. \"\"\" attempts = 1 if not retry else self.max_retries for attempt in range(1, attempts + 1): try: if self.client: self.disconnect() # Close any existing connection self.client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) if self.no_delay: self.client.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1) self.client.setsockopt(socket.IPPROTO_IP , socket.IP_TOS, 46 << 2) # Set TOS for low latency #self.client.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_TCLASS, 0xB8) self.logger.debug(\"Nagle's algorithm disabled for better latency. TOS set to EF.\") '''try: create_qos_policy_on_port(self.port) self.logger.debug(\"QoS2 DSCP EF applied via QOSAddSocketToFlow/QOSSetFlow2\") except Exception as e: self.logger.warning(f\"QoS2 setup failed: {e}\")''' self.client.settimeout(self.timeout) self.client.connect((self.host, self.port)) self.connected = True self.logger.info(f\"Connected to server at {self.host}:{self.port}\") return True except socket.error as e: if attempt < attempts: self.logger.warning(f\"Connection attempt {attempt} failed: {e}. Retrying in {self.retry_delay}s...\") time.sleep(self.retry_delay) else: self.logger.error(f\"Failed to connect after {attempts} attempts: {e}\") self.client = None self.connected = False raise ConnectionError(f\"Failed to connect to {self.host}:{self.port}: {e}\") return False disconnect() Close the TCP connection. Notes Resets the socket and updates state to disconnected. Source code in python/neuro_rpc/Client.py def disconnect(self) -> None: \"\"\" Close the TCP connection. Notes: Resets the socket and updates state to disconnected. \"\"\" if self.client: try: self.client.close() except socket.error as e: self.logger.warning(f\"Error during disconnection: {e}\") finally: self.client = None self.connected = False self.logger.info(\"Disconnected from server\") echo(message='test') Send an echo request and track its execution time. Parameters: message ( str , default: 'test' ) \u2013 String to send. Source code in python/neuro_rpc/Client.py def echo(self, message='test'): \"\"\" Send an ``echo`` request and track its execution time. Args: message (str): String to send. \"\"\" if isinstance(message, str): size, data, tail = self.rpc(\"echo\", {'Message': message}) data = json.loads(data) exec_time = tail self.handler.process_message(data) self.handler.tracker.set_exec_time(data['id'], exec_time) else: self.logger.error(\"echo message must be a string\") echo_benchmark() Run a benchmark using echo requests with increasing payload sizes. Iterates over multiple message sizes, repeating each size multiple times, and records metrics through the Benchmark tracker. Source code in python/neuro_rpc/Client.py def echo_benchmark(self): \"\"\" Run a benchmark using echo requests with increasing payload sizes. Iterates over multiple message sizes, repeating each size multiple times, and records metrics through the Benchmark tracker. \"\"\" import numpy sizes = numpy.linspace(0, 9600, 21, dtype=int) iter = 10 self.handler.tracker.start_benchmark() for i, size in enumerate(sizes): size_progress = (i / len(sizes)) * 100 # self.logger.info(f\"Testing payload size {size} bytes - {size_progress:.1f}% complete\") for j in range(iter): payload = \"X\" * size self.echo(payload) self.handler.tracker.stop_benchmark() self.handler.tracker.start_benchmark() for i, size in enumerate(sizes): for j in range(iter): payload = \"X\" * size self.echo(payload) self.handler.tracker.stop_benchmark() self.handler.tracker.start_benchmark() for i, size in enumerate(sizes): for j in range(iter): payload = \"X\" * size self.echo(payload) self.handler.tracker.stop_benchmark() ensure_connected() Verify connection before sending/receiving. Raises: ConnectionError \u2013 If not connected. Source code in python/neuro_rpc/Client.py def ensure_connected(self) -> None: \"\"\" Verify connection before sending/receiving. Raises: ConnectionError: If not connected. \"\"\" if not self.connected or self.client is None: raise ConnectionError(\"Not connected to server. Call connect() first.\") receive_message(timeout=None, partial_timeout=None) Receive and parse a JSON message. Parameters: timeout ( float | None , default: None ) \u2013 Optional override for socket timeout. partial_timeout ( float | None , default: None ) \u2013 Timeout for the remainder after the header. Returns: dict ( Any ) \u2013 Parsed JSON response. Raises: ConnectionError \u2013 If disconnected. TimeoutError \u2013 If operation times out. MessageError \u2013 If parsing fails. Source code in python/neuro_rpc/Client.py def receive_message(self, timeout: Optional[float] = None, partial_timeout: Optional[float] = None) -> Any: \"\"\" Receive and parse a JSON message. Args: timeout (float | None): Optional override for socket timeout. partial_timeout (float | None): Timeout for the remainder after the header. Returns: dict: Parsed JSON response. Raises: ConnectionError: If disconnected. TimeoutError: If operation times out. MessageError: If parsing fails. \"\"\" self.ensure_connected() # Set timeout for this operation if provided original_timeout = None if timeout is not None: original_timeout = self.client.gettimeout() self.client.settimeout(timeout) try: # Read the message size message_size_data = self._recv_exactly(4) # Unpack the message size message_size = struct.unpack(self.endian, message_size_data)[0] # Set partial timeout for remainder of message if specified if partial_timeout is not None and original_timeout is None: original_timeout = self.client.gettimeout() self.client.settimeout(partial_timeout) # Read the actual message based on the size message_data = self._recv_exactly(message_size) # Decode and parse the message response = json.loads(message_data.decode(self.encoding)) return response except socket.timeout as e: self.logger.error(f\"Timeout receiving message: {e}\") raise TimeoutError(f\"Timed out waiting for response: {e}\") except socket.error as e: self.logger.error(f\"Socket error: {e}\") self.connected = False # Mark as disconnected since the connection probably dropped raise ConnectionError(f\"Connection error while receiving: {e}\") except (struct.error, json.JSONDecodeError) as e: self.logger.error(f\"Error parsing message: {e}\") raise MessageError(f\"Invalid message format: {e}\") finally: # Restore original timeout if it was changed if original_timeout is not None: self.client.settimeout(original_timeout) recv_packet() Receive a framed packet. Returns: \u2013 tuple[int, bytes, int] | None: (size, data_bytes, trailer_int) or None on error. Source code in python/neuro_rpc/Client.py def recv_packet(self): \"\"\" Receive a framed packet. Returns: tuple[int, bytes, int] | None: ``(size, data_bytes, trailer_int)`` or ``None`` on error. \"\"\" try: length_bytes = self._recv_exactly(self.header_bytes) size = int.from_bytes(length_bytes) full_packet = self._recv_exactly(size) data, tail = self._unbuild_packet(full_packet, size) # print(f\"size: {size}, tail {tail}\") return size, data, tail except Exception as e: self.logger.error(f\"Error receiving packet: {e}\") return None rpc(method, params, response=True) Perform an RPC call using Proxy encoding. Parameters: method ( str ) \u2013 RPC method name. params ( dict ) \u2013 Parameters. response ( bool , default: True ) \u2013 Whether to wait for and return a response. Returns: \u2013 tuple[int, str, int] | None: (size, json_str, tail) if response=True , else None . Source code in python/neuro_rpc/Client.py def rpc(self, method, params, response=True): \"\"\" Perform an RPC call using Proxy encoding. Args: method (str): RPC method name. params (dict): Parameters. response (bool): Whether to wait for and return a response. Returns: tuple[int, str, int] | None: ``(size, json_str, tail)`` if ``response=True``, else ``None``. \"\"\" proxy = Proxy() request = self.handler.create_request(method, params) request, hdr_tree = proxy.to_act(request) packet = self._build_packet(request) if response: self.send_packet(packet) size, data, tail = self.recv_packet() data = proxy.from_act(data, hdr_tree) tail = tail data = json.dumps(data, cls=NpEncoder) return size, data, tail else: self.send_packet(packet) return None send_and_receive(message, timeout=None, retry_on_error=True) Convenience wrapper to send and immediately receive a message. Parameters: message ( dict ) \u2013 Message to send. timeout ( float | None , default: None ) \u2013 Optional receive timeout. retry_on_error ( bool , default: True ) \u2013 Whether to retry on send errors. Returns: dict ( Any ) \u2013 Parsed JSON response. Source code in python/neuro_rpc/Client.py def send_and_receive(self, message: Dict[str, Any], timeout: Optional[float] = None, retry_on_error: bool = True) -> Any: \"\"\" Convenience wrapper to send and immediately receive a message. Args: message (dict): Message to send. timeout (float | None): Optional receive timeout. retry_on_error (bool): Whether to retry on send errors. Returns: dict: Parsed JSON response. \"\"\" self.send_message(message, retry_on_error) return self.receive_message(timeout) send_message(message, retry_on_error=True) Send a JSON message with retry support. Parameters: message ( dict ) \u2013 JSON-compatible message. retry_on_error ( bool , default: True ) \u2013 Whether to retry on socket errors. Returns: bool ( bool ) \u2013 True if sent successfully. Raises: ConnectionError \u2013 If not connected. MessageError \u2013 If serialization or send fails. Source code in python/neuro_rpc/Client.py def send_message(self, message: Dict[str, Any], retry_on_error: bool = True) -> bool: \"\"\" Send a JSON message with retry support. Args: message (dict): JSON-compatible message. retry_on_error (bool): Whether to retry on socket errors. Returns: bool: True if sent successfully. Raises: ConnectionError: If not connected. MessageError: If serialization or send fails. \"\"\" self.ensure_connected() attempts = 1 if not retry_on_error else self.max_retries for attempt in range(1, attempts + 1): try: # Serialize message as JSON message_json = json.dumps(message) # Send the size of the message first message_size = len(message_json) self.client.sendall(struct.pack(self.endian, message_size)) # Send the actual message self.client.sendall(message_json.encode(self.encoding)) #self.logger.debug(f\"Sent: {message}\") return True except (socket.error, struct.error) as e: if attempt < attempts: self.logger.warning(f\"Send attempt {attempt} failed: {e}. Retrying...\") # Try to reconnect before retrying try: self.connect(retry=False) except ConnectionError: pass # Will be caught in the next iteration else: self.logger.error(f\"Failed to send message after {attempts} attempts: {e}\") raise MessageError(f\"Failed to send message: {e}\") return False send_packet(packet) Send a raw packet. Parameters: packet ( bytes ) \u2013 Complete framed packet. Returns: bool \u2013 True if sent successfully. Source code in python/neuro_rpc/Client.py def send_packet(self, packet): \"\"\" Send a raw packet. Args: packet (bytes): Complete framed packet. Returns: bool: True if sent successfully. \"\"\" try: # Send packet self.client.sendall(packet) return True except Exception as e: self.logger.error(f\"Error sending packet: {e}\") return False start() Start the client in a background thread. Notes Spawns a daemon thread that calls connect() and maintains the connection. Source code in python/neuro_rpc/Client.py def start(self): \"\"\" Start the client in a background thread. Notes: Spawns a daemon thread that calls ``connect()`` and maintains the connection. \"\"\" if self.thread_running: self.logger.error(f\"Client is already running in thread {self.client_thread.name}\") return # Start the client in a separate thread def client_thread_func(): try: self.logger.debug(f\"Starting client on thread {threading.current_thread().name}\") self.connect() self.thread_running = True # Main thread loop while self.thread_running: # TODO: handle reconnection logic here time.sleep(0.1) # Prevent CPU hogging except Exception as e: self.logger.error(f\"Client error: {e}\") finally: self.logger.info(\"Client thread terminated\") self.thread_running = False self.client_thread = threading.Thread( target=client_thread_func, name=\"ClientThread\", daemon=True # Make it a daemon so it exits when the main thread exits ) self.client_thread.start() self.logger.debug(\"Client started in background thread\") stop() Stop the client thread and disconnect. Calls disconnect() , stops monitoring, and joins the thread. Source code in python/neuro_rpc/Client.py def stop(self): \"\"\" Stop the client thread and disconnect. Calls ``disconnect()``, stops monitoring, and joins the thread. \"\"\" if not self.thread_running: self.logger.error(\"Client is not running\") return self.logger.info(\"Stopping client...\") try: self.disconnect() # Stop monitor tracker self.handler.tracker.stop_monitoring() # Wait for thread to terminate (with timeout) self.client_thread.join(timeout=2.0) if self.client_thread.is_alive(): self.logger.warning(\"Client thread did not terminate properly\") self.thread_running = False self.logger.info(\"Client stopped\") except Exception as e: self.logger.error(f\"Error stopping client: {e}\") ConnectionError Bases: Exception Raised for connection-related errors (e.g., failed connect or lost connection). MessageError Bases: Exception Raised when a message cannot be serialized, sent, or parsed. TimeoutError Bases: Exception Raised when a receive operation exceeds the configured timeout.","title":"Benchmark"},{"location":"reference/Benchmark/#client","text":"TCP client for framed JSON-RPC-like communication. This module implements a Python client that communicates with a LabVIEW/CompactRIO server using a custom framed JSON message protocol. It manages socket lifecycle, message serialization, connection retries, and integration with the RPC stack. Notes All socket operations are blocking. Background operation is achieved by running the client in a thread.","title":"Client"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client","text":"TCP Client for framed JSON messages. Manages connection lifecycle, sending/receiving messages, background thread execution, and integration with RPC handlers and trackers. Initialize a Client instance with connection parameters. Parameters: host ( str , default: '127.0.0.1' ) \u2013 Target hostname or IP address. port ( int , default: 6363 ) \u2013 TCP port of the server. encoding ( str , default: 'UTF-8' ) \u2013 Encoding for JSON messages. endian ( str , default: '>I' ) \u2013 Struct format for message length (e.g., '>I' big-endian). timeout ( float , default: 10.0 ) \u2013 Socket timeout in seconds. max_retries ( int , default: 3 ) \u2013 Maximum number of connection attempts. retry_delay ( float , default: 1.0 ) \u2013 Delay between retry attempts in seconds. handler \u2013 Optional RPC handler, defaults to RPCMethods() . no_delay ( bool , default: True ) \u2013 If True, disables Nagle\u2019s algorithm and sets DSCP EF. Source code in python/neuro_rpc/Client.py def __init__(self, host: str = \"127.0.0.1\", port: int = 6363, encoding: str = 'UTF-8', endian: str = '>I', timeout: float = 10.0, max_retries: int = 3, retry_delay: float = 1.0, handler=None, no_delay = True): \"\"\" Initialize a Client instance with connection parameters. Args: host (str): Target hostname or IP address. port (int): TCP port of the server. encoding (str): Encoding for JSON messages. endian (str): Struct format for message length (e.g., ``'>I'`` big-endian). timeout (float): Socket timeout in seconds. max_retries (int): Maximum number of connection attempts. retry_delay (float): Delay between retry attempts in seconds. handler: Optional RPC handler, defaults to ``RPCMethods()``. no_delay (bool): If True, disables Nagle\u2019s algorithm and sets DSCP EF. \"\"\" self.host = host self.port = port self.encoding = encoding self.endian = endian self.timeout = timeout self.max_retries = max_retries self.retry_delay = retry_delay self.no_delay = no_delay self.client = None self.client_thread = None self.connected = False self.thread_running = False self.logger = Logger.get_logger(self.__class__.__name__()) # Handling methods self.handler = RPCMethods() self.header_bytes = 4 self.trailer_bytes = 4","title":"Client"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.connect","text":"Establish a TCP connection with retry support. Parameters: retry ( bool , default: True ) \u2013 Whether to retry failed attempts. Returns: bool ( bool ) \u2013 True if connected successfully. Raises: ConnectionError \u2013 If all attempts fail. Source code in python/neuro_rpc/Client.py def connect(self, retry: bool = True) -> bool: \"\"\" Establish a TCP connection with retry support. Args: retry (bool): Whether to retry failed attempts. Returns: bool: True if connected successfully. Raises: ConnectionError: If all attempts fail. \"\"\" attempts = 1 if not retry else self.max_retries for attempt in range(1, attempts + 1): try: if self.client: self.disconnect() # Close any existing connection self.client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) if self.no_delay: self.client.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1) self.client.setsockopt(socket.IPPROTO_IP , socket.IP_TOS, 46 << 2) # Set TOS for low latency #self.client.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_TCLASS, 0xB8) self.logger.debug(\"Nagle's algorithm disabled for better latency. TOS set to EF.\") '''try: create_qos_policy_on_port(self.port) self.logger.debug(\"QoS2 DSCP EF applied via QOSAddSocketToFlow/QOSSetFlow2\") except Exception as e: self.logger.warning(f\"QoS2 setup failed: {e}\")''' self.client.settimeout(self.timeout) self.client.connect((self.host, self.port)) self.connected = True self.logger.info(f\"Connected to server at {self.host}:{self.port}\") return True except socket.error as e: if attempt < attempts: self.logger.warning(f\"Connection attempt {attempt} failed: {e}. Retrying in {self.retry_delay}s...\") time.sleep(self.retry_delay) else: self.logger.error(f\"Failed to connect after {attempts} attempts: {e}\") self.client = None self.connected = False raise ConnectionError(f\"Failed to connect to {self.host}:{self.port}: {e}\") return False","title":"connect"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.disconnect","text":"Close the TCP connection. Notes Resets the socket and updates state to disconnected. Source code in python/neuro_rpc/Client.py def disconnect(self) -> None: \"\"\" Close the TCP connection. Notes: Resets the socket and updates state to disconnected. \"\"\" if self.client: try: self.client.close() except socket.error as e: self.logger.warning(f\"Error during disconnection: {e}\") finally: self.client = None self.connected = False self.logger.info(\"Disconnected from server\")","title":"disconnect"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.echo","text":"Send an echo request and track its execution time. Parameters: message ( str , default: 'test' ) \u2013 String to send. Source code in python/neuro_rpc/Client.py def echo(self, message='test'): \"\"\" Send an ``echo`` request and track its execution time. Args: message (str): String to send. \"\"\" if isinstance(message, str): size, data, tail = self.rpc(\"echo\", {'Message': message}) data = json.loads(data) exec_time = tail self.handler.process_message(data) self.handler.tracker.set_exec_time(data['id'], exec_time) else: self.logger.error(\"echo message must be a string\")","title":"echo"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.echo_benchmark","text":"Run a benchmark using echo requests with increasing payload sizes. Iterates over multiple message sizes, repeating each size multiple times, and records metrics through the Benchmark tracker. Source code in python/neuro_rpc/Client.py def echo_benchmark(self): \"\"\" Run a benchmark using echo requests with increasing payload sizes. Iterates over multiple message sizes, repeating each size multiple times, and records metrics through the Benchmark tracker. \"\"\" import numpy sizes = numpy.linspace(0, 9600, 21, dtype=int) iter = 10 self.handler.tracker.start_benchmark() for i, size in enumerate(sizes): size_progress = (i / len(sizes)) * 100 # self.logger.info(f\"Testing payload size {size} bytes - {size_progress:.1f}% complete\") for j in range(iter): payload = \"X\" * size self.echo(payload) self.handler.tracker.stop_benchmark() self.handler.tracker.start_benchmark() for i, size in enumerate(sizes): for j in range(iter): payload = \"X\" * size self.echo(payload) self.handler.tracker.stop_benchmark() self.handler.tracker.start_benchmark() for i, size in enumerate(sizes): for j in range(iter): payload = \"X\" * size self.echo(payload) self.handler.tracker.stop_benchmark()","title":"echo_benchmark"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.ensure_connected","text":"Verify connection before sending/receiving. Raises: ConnectionError \u2013 If not connected. Source code in python/neuro_rpc/Client.py def ensure_connected(self) -> None: \"\"\" Verify connection before sending/receiving. Raises: ConnectionError: If not connected. \"\"\" if not self.connected or self.client is None: raise ConnectionError(\"Not connected to server. Call connect() first.\")","title":"ensure_connected"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.receive_message","text":"Receive and parse a JSON message. Parameters: timeout ( float | None , default: None ) \u2013 Optional override for socket timeout. partial_timeout ( float | None , default: None ) \u2013 Timeout for the remainder after the header. Returns: dict ( Any ) \u2013 Parsed JSON response. Raises: ConnectionError \u2013 If disconnected. TimeoutError \u2013 If operation times out. MessageError \u2013 If parsing fails. Source code in python/neuro_rpc/Client.py def receive_message(self, timeout: Optional[float] = None, partial_timeout: Optional[float] = None) -> Any: \"\"\" Receive and parse a JSON message. Args: timeout (float | None): Optional override for socket timeout. partial_timeout (float | None): Timeout for the remainder after the header. Returns: dict: Parsed JSON response. Raises: ConnectionError: If disconnected. TimeoutError: If operation times out. MessageError: If parsing fails. \"\"\" self.ensure_connected() # Set timeout for this operation if provided original_timeout = None if timeout is not None: original_timeout = self.client.gettimeout() self.client.settimeout(timeout) try: # Read the message size message_size_data = self._recv_exactly(4) # Unpack the message size message_size = struct.unpack(self.endian, message_size_data)[0] # Set partial timeout for remainder of message if specified if partial_timeout is not None and original_timeout is None: original_timeout = self.client.gettimeout() self.client.settimeout(partial_timeout) # Read the actual message based on the size message_data = self._recv_exactly(message_size) # Decode and parse the message response = json.loads(message_data.decode(self.encoding)) return response except socket.timeout as e: self.logger.error(f\"Timeout receiving message: {e}\") raise TimeoutError(f\"Timed out waiting for response: {e}\") except socket.error as e: self.logger.error(f\"Socket error: {e}\") self.connected = False # Mark as disconnected since the connection probably dropped raise ConnectionError(f\"Connection error while receiving: {e}\") except (struct.error, json.JSONDecodeError) as e: self.logger.error(f\"Error parsing message: {e}\") raise MessageError(f\"Invalid message format: {e}\") finally: # Restore original timeout if it was changed if original_timeout is not None: self.client.settimeout(original_timeout)","title":"receive_message"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.recv_packet","text":"Receive a framed packet. Returns: \u2013 tuple[int, bytes, int] | None: (size, data_bytes, trailer_int) or None on error. Source code in python/neuro_rpc/Client.py def recv_packet(self): \"\"\" Receive a framed packet. Returns: tuple[int, bytes, int] | None: ``(size, data_bytes, trailer_int)`` or ``None`` on error. \"\"\" try: length_bytes = self._recv_exactly(self.header_bytes) size = int.from_bytes(length_bytes) full_packet = self._recv_exactly(size) data, tail = self._unbuild_packet(full_packet, size) # print(f\"size: {size}, tail {tail}\") return size, data, tail except Exception as e: self.logger.error(f\"Error receiving packet: {e}\") return None","title":"recv_packet"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.rpc","text":"Perform an RPC call using Proxy encoding. Parameters: method ( str ) \u2013 RPC method name. params ( dict ) \u2013 Parameters. response ( bool , default: True ) \u2013 Whether to wait for and return a response. Returns: \u2013 tuple[int, str, int] | None: (size, json_str, tail) if response=True , else None . Source code in python/neuro_rpc/Client.py def rpc(self, method, params, response=True): \"\"\" Perform an RPC call using Proxy encoding. Args: method (str): RPC method name. params (dict): Parameters. response (bool): Whether to wait for and return a response. Returns: tuple[int, str, int] | None: ``(size, json_str, tail)`` if ``response=True``, else ``None``. \"\"\" proxy = Proxy() request = self.handler.create_request(method, params) request, hdr_tree = proxy.to_act(request) packet = self._build_packet(request) if response: self.send_packet(packet) size, data, tail = self.recv_packet() data = proxy.from_act(data, hdr_tree) tail = tail data = json.dumps(data, cls=NpEncoder) return size, data, tail else: self.send_packet(packet) return None","title":"rpc"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.send_and_receive","text":"Convenience wrapper to send and immediately receive a message. Parameters: message ( dict ) \u2013 Message to send. timeout ( float | None , default: None ) \u2013 Optional receive timeout. retry_on_error ( bool , default: True ) \u2013 Whether to retry on send errors. Returns: dict ( Any ) \u2013 Parsed JSON response. Source code in python/neuro_rpc/Client.py def send_and_receive(self, message: Dict[str, Any], timeout: Optional[float] = None, retry_on_error: bool = True) -> Any: \"\"\" Convenience wrapper to send and immediately receive a message. Args: message (dict): Message to send. timeout (float | None): Optional receive timeout. retry_on_error (bool): Whether to retry on send errors. Returns: dict: Parsed JSON response. \"\"\" self.send_message(message, retry_on_error) return self.receive_message(timeout)","title":"send_and_receive"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.send_message","text":"Send a JSON message with retry support. Parameters: message ( dict ) \u2013 JSON-compatible message. retry_on_error ( bool , default: True ) \u2013 Whether to retry on socket errors. Returns: bool ( bool ) \u2013 True if sent successfully. Raises: ConnectionError \u2013 If not connected. MessageError \u2013 If serialization or send fails. Source code in python/neuro_rpc/Client.py def send_message(self, message: Dict[str, Any], retry_on_error: bool = True) -> bool: \"\"\" Send a JSON message with retry support. Args: message (dict): JSON-compatible message. retry_on_error (bool): Whether to retry on socket errors. Returns: bool: True if sent successfully. Raises: ConnectionError: If not connected. MessageError: If serialization or send fails. \"\"\" self.ensure_connected() attempts = 1 if not retry_on_error else self.max_retries for attempt in range(1, attempts + 1): try: # Serialize message as JSON message_json = json.dumps(message) # Send the size of the message first message_size = len(message_json) self.client.sendall(struct.pack(self.endian, message_size)) # Send the actual message self.client.sendall(message_json.encode(self.encoding)) #self.logger.debug(f\"Sent: {message}\") return True except (socket.error, struct.error) as e: if attempt < attempts: self.logger.warning(f\"Send attempt {attempt} failed: {e}. Retrying...\") # Try to reconnect before retrying try: self.connect(retry=False) except ConnectionError: pass # Will be caught in the next iteration else: self.logger.error(f\"Failed to send message after {attempts} attempts: {e}\") raise MessageError(f\"Failed to send message: {e}\") return False","title":"send_message"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.send_packet","text":"Send a raw packet. Parameters: packet ( bytes ) \u2013 Complete framed packet. Returns: bool \u2013 True if sent successfully. Source code in python/neuro_rpc/Client.py def send_packet(self, packet): \"\"\" Send a raw packet. Args: packet (bytes): Complete framed packet. Returns: bool: True if sent successfully. \"\"\" try: # Send packet self.client.sendall(packet) return True except Exception as e: self.logger.error(f\"Error sending packet: {e}\") return False","title":"send_packet"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.start","text":"Start the client in a background thread. Notes Spawns a daemon thread that calls connect() and maintains the connection. Source code in python/neuro_rpc/Client.py def start(self): \"\"\" Start the client in a background thread. Notes: Spawns a daemon thread that calls ``connect()`` and maintains the connection. \"\"\" if self.thread_running: self.logger.error(f\"Client is already running in thread {self.client_thread.name}\") return # Start the client in a separate thread def client_thread_func(): try: self.logger.debug(f\"Starting client on thread {threading.current_thread().name}\") self.connect() self.thread_running = True # Main thread loop while self.thread_running: # TODO: handle reconnection logic here time.sleep(0.1) # Prevent CPU hogging except Exception as e: self.logger.error(f\"Client error: {e}\") finally: self.logger.info(\"Client thread terminated\") self.thread_running = False self.client_thread = threading.Thread( target=client_thread_func, name=\"ClientThread\", daemon=True # Make it a daemon so it exits when the main thread exits ) self.client_thread.start() self.logger.debug(\"Client started in background thread\")","title":"start"},{"location":"reference/Benchmark/#neuro_rpc.Client.Client.stop","text":"Stop the client thread and disconnect. Calls disconnect() , stops monitoring, and joins the thread. Source code in python/neuro_rpc/Client.py def stop(self): \"\"\" Stop the client thread and disconnect. Calls ``disconnect()``, stops monitoring, and joins the thread. \"\"\" if not self.thread_running: self.logger.error(\"Client is not running\") return self.logger.info(\"Stopping client...\") try: self.disconnect() # Stop monitor tracker self.handler.tracker.stop_monitoring() # Wait for thread to terminate (with timeout) self.client_thread.join(timeout=2.0) if self.client_thread.is_alive(): self.logger.warning(\"Client thread did not terminate properly\") self.thread_running = False self.logger.info(\"Client stopped\") except Exception as e: self.logger.error(f\"Error stopping client: {e}\")","title":"stop"},{"location":"reference/Benchmark/#neuro_rpc.Client.ConnectionError","text":"Bases: Exception Raised for connection-related errors (e.g., failed connect or lost connection).","title":"ConnectionError"},{"location":"reference/Benchmark/#neuro_rpc.Client.MessageError","text":"Bases: Exception Raised when a message cannot be serialized, sent, or parsed.","title":"MessageError"},{"location":"reference/Benchmark/#neuro_rpc.Client.TimeoutError","text":"Bases: Exception Raised when a receive operation exceeds the configured timeout.","title":"TimeoutError"},{"location":"reference/Client/","text":"Client TCP client for framed JSON-RPC-like communication. This module implements a Python client that communicates with a LabVIEW/CompactRIO server using a custom framed JSON message protocol. It manages socket lifecycle, message serialization, connection retries, and integration with the RPC stack. Notes All socket operations are blocking. Background operation is achieved by running the client in a thread. Client(host='127.0.0.1', port=6363, encoding='UTF-8', endian='>I', timeout=10.0, max_retries=3, retry_delay=1.0, handler=None, no_delay=True) TCP Client for framed JSON messages. Manages connection lifecycle, sending/receiving messages, background thread execution, and integration with RPC handlers and trackers. Initialize a Client instance with connection parameters. Parameters: host ( str , default: '127.0.0.1' ) \u2013 Target hostname or IP address. port ( int , default: 6363 ) \u2013 TCP port of the server. encoding ( str , default: 'UTF-8' ) \u2013 Encoding for JSON messages. endian ( str , default: '>I' ) \u2013 Struct format for message length (e.g., '>I' big-endian). timeout ( float , default: 10.0 ) \u2013 Socket timeout in seconds. max_retries ( int , default: 3 ) \u2013 Maximum number of connection attempts. retry_delay ( float , default: 1.0 ) \u2013 Delay between retry attempts in seconds. handler \u2013 Optional RPC handler, defaults to RPCMethods() . no_delay ( bool , default: True ) \u2013 If True, disables Nagle\u2019s algorithm and sets DSCP EF. Source code in python/neuro_rpc/Client.py def __init__(self, host: str = \"127.0.0.1\", port: int = 6363, encoding: str = 'UTF-8', endian: str = '>I', timeout: float = 10.0, max_retries: int = 3, retry_delay: float = 1.0, handler=None, no_delay = True): \"\"\" Initialize a Client instance with connection parameters. Args: host (str): Target hostname or IP address. port (int): TCP port of the server. encoding (str): Encoding for JSON messages. endian (str): Struct format for message length (e.g., ``'>I'`` big-endian). timeout (float): Socket timeout in seconds. max_retries (int): Maximum number of connection attempts. retry_delay (float): Delay between retry attempts in seconds. handler: Optional RPC handler, defaults to ``RPCMethods()``. no_delay (bool): If True, disables Nagle\u2019s algorithm and sets DSCP EF. \"\"\" self.host = host self.port = port self.encoding = encoding self.endian = endian self.timeout = timeout self.max_retries = max_retries self.retry_delay = retry_delay self.no_delay = no_delay self.client = None self.client_thread = None self.connected = False self.thread_running = False self.logger = Logger.get_logger(self.__class__.__name__()) # Handling methods self.handler = RPCMethods() self.header_bytes = 4 self.trailer_bytes = 4 connect(retry=True) Establish a TCP connection with retry support. Parameters: retry ( bool , default: True ) \u2013 Whether to retry failed attempts. Returns: bool ( bool ) \u2013 True if connected successfully. Raises: ConnectionError \u2013 If all attempts fail. Source code in python/neuro_rpc/Client.py def connect(self, retry: bool = True) -> bool: \"\"\" Establish a TCP connection with retry support. Args: retry (bool): Whether to retry failed attempts. Returns: bool: True if connected successfully. Raises: ConnectionError: If all attempts fail. \"\"\" attempts = 1 if not retry else self.max_retries for attempt in range(1, attempts + 1): try: if self.client: self.disconnect() # Close any existing connection self.client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) if self.no_delay: self.client.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1) self.client.setsockopt(socket.IPPROTO_IP , socket.IP_TOS, 46 << 2) # Set TOS for low latency #self.client.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_TCLASS, 0xB8) self.logger.debug(\"Nagle's algorithm disabled for better latency. TOS set to EF.\") '''try: create_qos_policy_on_port(self.port) self.logger.debug(\"QoS2 DSCP EF applied via QOSAddSocketToFlow/QOSSetFlow2\") except Exception as e: self.logger.warning(f\"QoS2 setup failed: {e}\")''' self.client.settimeout(self.timeout) self.client.connect((self.host, self.port)) self.connected = True self.logger.info(f\"Connected to server at {self.host}:{self.port}\") return True except socket.error as e: if attempt < attempts: self.logger.warning(f\"Connection attempt {attempt} failed: {e}. Retrying in {self.retry_delay}s...\") time.sleep(self.retry_delay) else: self.logger.error(f\"Failed to connect after {attempts} attempts: {e}\") self.client = None self.connected = False raise ConnectionError(f\"Failed to connect to {self.host}:{self.port}: {e}\") return False disconnect() Close the TCP connection. Notes Resets the socket and updates state to disconnected. Source code in python/neuro_rpc/Client.py def disconnect(self) -> None: \"\"\" Close the TCP connection. Notes: Resets the socket and updates state to disconnected. \"\"\" if self.client: try: self.client.close() except socket.error as e: self.logger.warning(f\"Error during disconnection: {e}\") finally: self.client = None self.connected = False self.logger.info(\"Disconnected from server\") echo(message='test') Send an echo request and track its execution time. Parameters: message ( str , default: 'test' ) \u2013 String to send. Source code in python/neuro_rpc/Client.py def echo(self, message='test'): \"\"\" Send an ``echo`` request and track its execution time. Args: message (str): String to send. \"\"\" if isinstance(message, str): size, data, tail = self.rpc(\"echo\", {'Message': message}) data = json.loads(data) exec_time = tail self.handler.process_message(data) self.handler.tracker.set_exec_time(data['id'], exec_time) else: self.logger.error(\"echo message must be a string\") echo_benchmark() Run a benchmark using echo requests with increasing payload sizes. Iterates over multiple message sizes, repeating each size multiple times, and records metrics through the Benchmark tracker. Source code in python/neuro_rpc/Client.py def echo_benchmark(self): \"\"\" Run a benchmark using echo requests with increasing payload sizes. Iterates over multiple message sizes, repeating each size multiple times, and records metrics through the Benchmark tracker. \"\"\" import numpy sizes = numpy.linspace(0, 9600, 21, dtype=int) iter = 10 self.handler.tracker.start_benchmark() for i, size in enumerate(sizes): size_progress = (i / len(sizes)) * 100 # self.logger.info(f\"Testing payload size {size} bytes - {size_progress:.1f}% complete\") for j in range(iter): payload = \"X\" * size self.echo(payload) self.handler.tracker.stop_benchmark() self.handler.tracker.start_benchmark() for i, size in enumerate(sizes): for j in range(iter): payload = \"X\" * size self.echo(payload) self.handler.tracker.stop_benchmark() self.handler.tracker.start_benchmark() for i, size in enumerate(sizes): for j in range(iter): payload = \"X\" * size self.echo(payload) self.handler.tracker.stop_benchmark() ensure_connected() Verify connection before sending/receiving. Raises: ConnectionError \u2013 If not connected. Source code in python/neuro_rpc/Client.py def ensure_connected(self) -> None: \"\"\" Verify connection before sending/receiving. Raises: ConnectionError: If not connected. \"\"\" if not self.connected or self.client is None: raise ConnectionError(\"Not connected to server. Call connect() first.\") receive_message(timeout=None, partial_timeout=None) Receive and parse a JSON message. Parameters: timeout ( float | None , default: None ) \u2013 Optional override for socket timeout. partial_timeout ( float | None , default: None ) \u2013 Timeout for the remainder after the header. Returns: dict ( Any ) \u2013 Parsed JSON response. Raises: ConnectionError \u2013 If disconnected. TimeoutError \u2013 If operation times out. MessageError \u2013 If parsing fails. Source code in python/neuro_rpc/Client.py def receive_message(self, timeout: Optional[float] = None, partial_timeout: Optional[float] = None) -> Any: \"\"\" Receive and parse a JSON message. Args: timeout (float | None): Optional override for socket timeout. partial_timeout (float | None): Timeout for the remainder after the header. Returns: dict: Parsed JSON response. Raises: ConnectionError: If disconnected. TimeoutError: If operation times out. MessageError: If parsing fails. \"\"\" self.ensure_connected() # Set timeout for this operation if provided original_timeout = None if timeout is not None: original_timeout = self.client.gettimeout() self.client.settimeout(timeout) try: # Read the message size message_size_data = self._recv_exactly(4) # Unpack the message size message_size = struct.unpack(self.endian, message_size_data)[0] # Set partial timeout for remainder of message if specified if partial_timeout is not None and original_timeout is None: original_timeout = self.client.gettimeout() self.client.settimeout(partial_timeout) # Read the actual message based on the size message_data = self._recv_exactly(message_size) # Decode and parse the message response = json.loads(message_data.decode(self.encoding)) return response except socket.timeout as e: self.logger.error(f\"Timeout receiving message: {e}\") raise TimeoutError(f\"Timed out waiting for response: {e}\") except socket.error as e: self.logger.error(f\"Socket error: {e}\") self.connected = False # Mark as disconnected since the connection probably dropped raise ConnectionError(f\"Connection error while receiving: {e}\") except (struct.error, json.JSONDecodeError) as e: self.logger.error(f\"Error parsing message: {e}\") raise MessageError(f\"Invalid message format: {e}\") finally: # Restore original timeout if it was changed if original_timeout is not None: self.client.settimeout(original_timeout) recv_packet() Receive a framed packet. Returns: \u2013 tuple[int, bytes, int] | None: (size, data_bytes, trailer_int) or None on error. Source code in python/neuro_rpc/Client.py def recv_packet(self): \"\"\" Receive a framed packet. Returns: tuple[int, bytes, int] | None: ``(size, data_bytes, trailer_int)`` or ``None`` on error. \"\"\" try: length_bytes = self._recv_exactly(self.header_bytes) size = int.from_bytes(length_bytes) full_packet = self._recv_exactly(size) data, tail = self._unbuild_packet(full_packet, size) # print(f\"size: {size}, tail {tail}\") return size, data, tail except Exception as e: self.logger.error(f\"Error receiving packet: {e}\") return None rpc(method, params, response=True) Perform an RPC call using Proxy encoding. Parameters: method ( str ) \u2013 RPC method name. params ( dict ) \u2013 Parameters. response ( bool , default: True ) \u2013 Whether to wait for and return a response. Returns: \u2013 tuple[int, str, int] | None: (size, json_str, tail) if response=True , else None . Source code in python/neuro_rpc/Client.py def rpc(self, method, params, response=True): \"\"\" Perform an RPC call using Proxy encoding. Args: method (str): RPC method name. params (dict): Parameters. response (bool): Whether to wait for and return a response. Returns: tuple[int, str, int] | None: ``(size, json_str, tail)`` if ``response=True``, else ``None``. \"\"\" proxy = Proxy() request = self.handler.create_request(method, params) request, hdr_tree = proxy.to_act(request) packet = self._build_packet(request) if response: self.send_packet(packet) size, data, tail = self.recv_packet() data = proxy.from_act(data, hdr_tree) tail = tail data = json.dumps(data, cls=NpEncoder) return size, data, tail else: self.send_packet(packet) return None send_and_receive(message, timeout=None, retry_on_error=True) Convenience wrapper to send and immediately receive a message. Parameters: message ( dict ) \u2013 Message to send. timeout ( float | None , default: None ) \u2013 Optional receive timeout. retry_on_error ( bool , default: True ) \u2013 Whether to retry on send errors. Returns: dict ( Any ) \u2013 Parsed JSON response. Source code in python/neuro_rpc/Client.py def send_and_receive(self, message: Dict[str, Any], timeout: Optional[float] = None, retry_on_error: bool = True) -> Any: \"\"\" Convenience wrapper to send and immediately receive a message. Args: message (dict): Message to send. timeout (float | None): Optional receive timeout. retry_on_error (bool): Whether to retry on send errors. Returns: dict: Parsed JSON response. \"\"\" self.send_message(message, retry_on_error) return self.receive_message(timeout) send_message(message, retry_on_error=True) Send a JSON message with retry support. Parameters: message ( dict ) \u2013 JSON-compatible message. retry_on_error ( bool , default: True ) \u2013 Whether to retry on socket errors. Returns: bool ( bool ) \u2013 True if sent successfully. Raises: ConnectionError \u2013 If not connected. MessageError \u2013 If serialization or send fails. Source code in python/neuro_rpc/Client.py def send_message(self, message: Dict[str, Any], retry_on_error: bool = True) -> bool: \"\"\" Send a JSON message with retry support. Args: message (dict): JSON-compatible message. retry_on_error (bool): Whether to retry on socket errors. Returns: bool: True if sent successfully. Raises: ConnectionError: If not connected. MessageError: If serialization or send fails. \"\"\" self.ensure_connected() attempts = 1 if not retry_on_error else self.max_retries for attempt in range(1, attempts + 1): try: # Serialize message as JSON message_json = json.dumps(message) # Send the size of the message first message_size = len(message_json) self.client.sendall(struct.pack(self.endian, message_size)) # Send the actual message self.client.sendall(message_json.encode(self.encoding)) #self.logger.debug(f\"Sent: {message}\") return True except (socket.error, struct.error) as e: if attempt < attempts: self.logger.warning(f\"Send attempt {attempt} failed: {e}. Retrying...\") # Try to reconnect before retrying try: self.connect(retry=False) except ConnectionError: pass # Will be caught in the next iteration else: self.logger.error(f\"Failed to send message after {attempts} attempts: {e}\") raise MessageError(f\"Failed to send message: {e}\") return False send_packet(packet) Send a raw packet. Parameters: packet ( bytes ) \u2013 Complete framed packet. Returns: bool \u2013 True if sent successfully. Source code in python/neuro_rpc/Client.py def send_packet(self, packet): \"\"\" Send a raw packet. Args: packet (bytes): Complete framed packet. Returns: bool: True if sent successfully. \"\"\" try: # Send packet self.client.sendall(packet) return True except Exception as e: self.logger.error(f\"Error sending packet: {e}\") return False start() Start the client in a background thread. Notes Spawns a daemon thread that calls connect() and maintains the connection. Source code in python/neuro_rpc/Client.py def start(self): \"\"\" Start the client in a background thread. Notes: Spawns a daemon thread that calls ``connect()`` and maintains the connection. \"\"\" if self.thread_running: self.logger.error(f\"Client is already running in thread {self.client_thread.name}\") return # Start the client in a separate thread def client_thread_func(): try: self.logger.debug(f\"Starting client on thread {threading.current_thread().name}\") self.connect() self.thread_running = True # Main thread loop while self.thread_running: # TODO: handle reconnection logic here time.sleep(0.1) # Prevent CPU hogging except Exception as e: self.logger.error(f\"Client error: {e}\") finally: self.logger.info(\"Client thread terminated\") self.thread_running = False self.client_thread = threading.Thread( target=client_thread_func, name=\"ClientThread\", daemon=True # Make it a daemon so it exits when the main thread exits ) self.client_thread.start() self.logger.debug(\"Client started in background thread\") stop() Stop the client thread and disconnect. Calls disconnect() , stops monitoring, and joins the thread. Source code in python/neuro_rpc/Client.py def stop(self): \"\"\" Stop the client thread and disconnect. Calls ``disconnect()``, stops monitoring, and joins the thread. \"\"\" if not self.thread_running: self.logger.error(\"Client is not running\") return self.logger.info(\"Stopping client...\") try: self.disconnect() # Stop monitor tracker self.handler.tracker.stop_monitoring() # Wait for thread to terminate (with timeout) self.client_thread.join(timeout=2.0) if self.client_thread.is_alive(): self.logger.warning(\"Client thread did not terminate properly\") self.thread_running = False self.logger.info(\"Client stopped\") except Exception as e: self.logger.error(f\"Error stopping client: {e}\") ConnectionError Bases: Exception Raised for connection-related errors (e.g., failed connect or lost connection). MessageError Bases: Exception Raised when a message cannot be serialized, sent, or parsed. TimeoutError Bases: Exception Raised when a receive operation exceeds the configured timeout.","title":"Client"},{"location":"reference/Client/#client","text":"TCP client for framed JSON-RPC-like communication. This module implements a Python client that communicates with a LabVIEW/CompactRIO server using a custom framed JSON message protocol. It manages socket lifecycle, message serialization, connection retries, and integration with the RPC stack. Notes All socket operations are blocking. Background operation is achieved by running the client in a thread.","title":"Client"},{"location":"reference/Client/#neuro_rpc.Client.Client","text":"TCP Client for framed JSON messages. Manages connection lifecycle, sending/receiving messages, background thread execution, and integration with RPC handlers and trackers. Initialize a Client instance with connection parameters. Parameters: host ( str , default: '127.0.0.1' ) \u2013 Target hostname or IP address. port ( int , default: 6363 ) \u2013 TCP port of the server. encoding ( str , default: 'UTF-8' ) \u2013 Encoding for JSON messages. endian ( str , default: '>I' ) \u2013 Struct format for message length (e.g., '>I' big-endian). timeout ( float , default: 10.0 ) \u2013 Socket timeout in seconds. max_retries ( int , default: 3 ) \u2013 Maximum number of connection attempts. retry_delay ( float , default: 1.0 ) \u2013 Delay between retry attempts in seconds. handler \u2013 Optional RPC handler, defaults to RPCMethods() . no_delay ( bool , default: True ) \u2013 If True, disables Nagle\u2019s algorithm and sets DSCP EF. Source code in python/neuro_rpc/Client.py def __init__(self, host: str = \"127.0.0.1\", port: int = 6363, encoding: str = 'UTF-8', endian: str = '>I', timeout: float = 10.0, max_retries: int = 3, retry_delay: float = 1.0, handler=None, no_delay = True): \"\"\" Initialize a Client instance with connection parameters. Args: host (str): Target hostname or IP address. port (int): TCP port of the server. encoding (str): Encoding for JSON messages. endian (str): Struct format for message length (e.g., ``'>I'`` big-endian). timeout (float): Socket timeout in seconds. max_retries (int): Maximum number of connection attempts. retry_delay (float): Delay between retry attempts in seconds. handler: Optional RPC handler, defaults to ``RPCMethods()``. no_delay (bool): If True, disables Nagle\u2019s algorithm and sets DSCP EF. \"\"\" self.host = host self.port = port self.encoding = encoding self.endian = endian self.timeout = timeout self.max_retries = max_retries self.retry_delay = retry_delay self.no_delay = no_delay self.client = None self.client_thread = None self.connected = False self.thread_running = False self.logger = Logger.get_logger(self.__class__.__name__()) # Handling methods self.handler = RPCMethods() self.header_bytes = 4 self.trailer_bytes = 4","title":"Client"},{"location":"reference/Client/#neuro_rpc.Client.Client.connect","text":"Establish a TCP connection with retry support. Parameters: retry ( bool , default: True ) \u2013 Whether to retry failed attempts. Returns: bool ( bool ) \u2013 True if connected successfully. Raises: ConnectionError \u2013 If all attempts fail. Source code in python/neuro_rpc/Client.py def connect(self, retry: bool = True) -> bool: \"\"\" Establish a TCP connection with retry support. Args: retry (bool): Whether to retry failed attempts. Returns: bool: True if connected successfully. Raises: ConnectionError: If all attempts fail. \"\"\" attempts = 1 if not retry else self.max_retries for attempt in range(1, attempts + 1): try: if self.client: self.disconnect() # Close any existing connection self.client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) if self.no_delay: self.client.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1) self.client.setsockopt(socket.IPPROTO_IP , socket.IP_TOS, 46 << 2) # Set TOS for low latency #self.client.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_TCLASS, 0xB8) self.logger.debug(\"Nagle's algorithm disabled for better latency. TOS set to EF.\") '''try: create_qos_policy_on_port(self.port) self.logger.debug(\"QoS2 DSCP EF applied via QOSAddSocketToFlow/QOSSetFlow2\") except Exception as e: self.logger.warning(f\"QoS2 setup failed: {e}\")''' self.client.settimeout(self.timeout) self.client.connect((self.host, self.port)) self.connected = True self.logger.info(f\"Connected to server at {self.host}:{self.port}\") return True except socket.error as e: if attempt < attempts: self.logger.warning(f\"Connection attempt {attempt} failed: {e}. Retrying in {self.retry_delay}s...\") time.sleep(self.retry_delay) else: self.logger.error(f\"Failed to connect after {attempts} attempts: {e}\") self.client = None self.connected = False raise ConnectionError(f\"Failed to connect to {self.host}:{self.port}: {e}\") return False","title":"connect"},{"location":"reference/Client/#neuro_rpc.Client.Client.disconnect","text":"Close the TCP connection. Notes Resets the socket and updates state to disconnected. Source code in python/neuro_rpc/Client.py def disconnect(self) -> None: \"\"\" Close the TCP connection. Notes: Resets the socket and updates state to disconnected. \"\"\" if self.client: try: self.client.close() except socket.error as e: self.logger.warning(f\"Error during disconnection: {e}\") finally: self.client = None self.connected = False self.logger.info(\"Disconnected from server\")","title":"disconnect"},{"location":"reference/Client/#neuro_rpc.Client.Client.echo","text":"Send an echo request and track its execution time. Parameters: message ( str , default: 'test' ) \u2013 String to send. Source code in python/neuro_rpc/Client.py def echo(self, message='test'): \"\"\" Send an ``echo`` request and track its execution time. Args: message (str): String to send. \"\"\" if isinstance(message, str): size, data, tail = self.rpc(\"echo\", {'Message': message}) data = json.loads(data) exec_time = tail self.handler.process_message(data) self.handler.tracker.set_exec_time(data['id'], exec_time) else: self.logger.error(\"echo message must be a string\")","title":"echo"},{"location":"reference/Client/#neuro_rpc.Client.Client.echo_benchmark","text":"Run a benchmark using echo requests with increasing payload sizes. Iterates over multiple message sizes, repeating each size multiple times, and records metrics through the Benchmark tracker. Source code in python/neuro_rpc/Client.py def echo_benchmark(self): \"\"\" Run a benchmark using echo requests with increasing payload sizes. Iterates over multiple message sizes, repeating each size multiple times, and records metrics through the Benchmark tracker. \"\"\" import numpy sizes = numpy.linspace(0, 9600, 21, dtype=int) iter = 10 self.handler.tracker.start_benchmark() for i, size in enumerate(sizes): size_progress = (i / len(sizes)) * 100 # self.logger.info(f\"Testing payload size {size} bytes - {size_progress:.1f}% complete\") for j in range(iter): payload = \"X\" * size self.echo(payload) self.handler.tracker.stop_benchmark() self.handler.tracker.start_benchmark() for i, size in enumerate(sizes): for j in range(iter): payload = \"X\" * size self.echo(payload) self.handler.tracker.stop_benchmark() self.handler.tracker.start_benchmark() for i, size in enumerate(sizes): for j in range(iter): payload = \"X\" * size self.echo(payload) self.handler.tracker.stop_benchmark()","title":"echo_benchmark"},{"location":"reference/Client/#neuro_rpc.Client.Client.ensure_connected","text":"Verify connection before sending/receiving. Raises: ConnectionError \u2013 If not connected. Source code in python/neuro_rpc/Client.py def ensure_connected(self) -> None: \"\"\" Verify connection before sending/receiving. Raises: ConnectionError: If not connected. \"\"\" if not self.connected or self.client is None: raise ConnectionError(\"Not connected to server. Call connect() first.\")","title":"ensure_connected"},{"location":"reference/Client/#neuro_rpc.Client.Client.receive_message","text":"Receive and parse a JSON message. Parameters: timeout ( float | None , default: None ) \u2013 Optional override for socket timeout. partial_timeout ( float | None , default: None ) \u2013 Timeout for the remainder after the header. Returns: dict ( Any ) \u2013 Parsed JSON response. Raises: ConnectionError \u2013 If disconnected. TimeoutError \u2013 If operation times out. MessageError \u2013 If parsing fails. Source code in python/neuro_rpc/Client.py def receive_message(self, timeout: Optional[float] = None, partial_timeout: Optional[float] = None) -> Any: \"\"\" Receive and parse a JSON message. Args: timeout (float | None): Optional override for socket timeout. partial_timeout (float | None): Timeout for the remainder after the header. Returns: dict: Parsed JSON response. Raises: ConnectionError: If disconnected. TimeoutError: If operation times out. MessageError: If parsing fails. \"\"\" self.ensure_connected() # Set timeout for this operation if provided original_timeout = None if timeout is not None: original_timeout = self.client.gettimeout() self.client.settimeout(timeout) try: # Read the message size message_size_data = self._recv_exactly(4) # Unpack the message size message_size = struct.unpack(self.endian, message_size_data)[0] # Set partial timeout for remainder of message if specified if partial_timeout is not None and original_timeout is None: original_timeout = self.client.gettimeout() self.client.settimeout(partial_timeout) # Read the actual message based on the size message_data = self._recv_exactly(message_size) # Decode and parse the message response = json.loads(message_data.decode(self.encoding)) return response except socket.timeout as e: self.logger.error(f\"Timeout receiving message: {e}\") raise TimeoutError(f\"Timed out waiting for response: {e}\") except socket.error as e: self.logger.error(f\"Socket error: {e}\") self.connected = False # Mark as disconnected since the connection probably dropped raise ConnectionError(f\"Connection error while receiving: {e}\") except (struct.error, json.JSONDecodeError) as e: self.logger.error(f\"Error parsing message: {e}\") raise MessageError(f\"Invalid message format: {e}\") finally: # Restore original timeout if it was changed if original_timeout is not None: self.client.settimeout(original_timeout)","title":"receive_message"},{"location":"reference/Client/#neuro_rpc.Client.Client.recv_packet","text":"Receive a framed packet. Returns: \u2013 tuple[int, bytes, int] | None: (size, data_bytes, trailer_int) or None on error. Source code in python/neuro_rpc/Client.py def recv_packet(self): \"\"\" Receive a framed packet. Returns: tuple[int, bytes, int] | None: ``(size, data_bytes, trailer_int)`` or ``None`` on error. \"\"\" try: length_bytes = self._recv_exactly(self.header_bytes) size = int.from_bytes(length_bytes) full_packet = self._recv_exactly(size) data, tail = self._unbuild_packet(full_packet, size) # print(f\"size: {size}, tail {tail}\") return size, data, tail except Exception as e: self.logger.error(f\"Error receiving packet: {e}\") return None","title":"recv_packet"},{"location":"reference/Client/#neuro_rpc.Client.Client.rpc","text":"Perform an RPC call using Proxy encoding. Parameters: method ( str ) \u2013 RPC method name. params ( dict ) \u2013 Parameters. response ( bool , default: True ) \u2013 Whether to wait for and return a response. Returns: \u2013 tuple[int, str, int] | None: (size, json_str, tail) if response=True , else None . Source code in python/neuro_rpc/Client.py def rpc(self, method, params, response=True): \"\"\" Perform an RPC call using Proxy encoding. Args: method (str): RPC method name. params (dict): Parameters. response (bool): Whether to wait for and return a response. Returns: tuple[int, str, int] | None: ``(size, json_str, tail)`` if ``response=True``, else ``None``. \"\"\" proxy = Proxy() request = self.handler.create_request(method, params) request, hdr_tree = proxy.to_act(request) packet = self._build_packet(request) if response: self.send_packet(packet) size, data, tail = self.recv_packet() data = proxy.from_act(data, hdr_tree) tail = tail data = json.dumps(data, cls=NpEncoder) return size, data, tail else: self.send_packet(packet) return None","title":"rpc"},{"location":"reference/Client/#neuro_rpc.Client.Client.send_and_receive","text":"Convenience wrapper to send and immediately receive a message. Parameters: message ( dict ) \u2013 Message to send. timeout ( float | None , default: None ) \u2013 Optional receive timeout. retry_on_error ( bool , default: True ) \u2013 Whether to retry on send errors. Returns: dict ( Any ) \u2013 Parsed JSON response. Source code in python/neuro_rpc/Client.py def send_and_receive(self, message: Dict[str, Any], timeout: Optional[float] = None, retry_on_error: bool = True) -> Any: \"\"\" Convenience wrapper to send and immediately receive a message. Args: message (dict): Message to send. timeout (float | None): Optional receive timeout. retry_on_error (bool): Whether to retry on send errors. Returns: dict: Parsed JSON response. \"\"\" self.send_message(message, retry_on_error) return self.receive_message(timeout)","title":"send_and_receive"},{"location":"reference/Client/#neuro_rpc.Client.Client.send_message","text":"Send a JSON message with retry support. Parameters: message ( dict ) \u2013 JSON-compatible message. retry_on_error ( bool , default: True ) \u2013 Whether to retry on socket errors. Returns: bool ( bool ) \u2013 True if sent successfully. Raises: ConnectionError \u2013 If not connected. MessageError \u2013 If serialization or send fails. Source code in python/neuro_rpc/Client.py def send_message(self, message: Dict[str, Any], retry_on_error: bool = True) -> bool: \"\"\" Send a JSON message with retry support. Args: message (dict): JSON-compatible message. retry_on_error (bool): Whether to retry on socket errors. Returns: bool: True if sent successfully. Raises: ConnectionError: If not connected. MessageError: If serialization or send fails. \"\"\" self.ensure_connected() attempts = 1 if not retry_on_error else self.max_retries for attempt in range(1, attempts + 1): try: # Serialize message as JSON message_json = json.dumps(message) # Send the size of the message first message_size = len(message_json) self.client.sendall(struct.pack(self.endian, message_size)) # Send the actual message self.client.sendall(message_json.encode(self.encoding)) #self.logger.debug(f\"Sent: {message}\") return True except (socket.error, struct.error) as e: if attempt < attempts: self.logger.warning(f\"Send attempt {attempt} failed: {e}. Retrying...\") # Try to reconnect before retrying try: self.connect(retry=False) except ConnectionError: pass # Will be caught in the next iteration else: self.logger.error(f\"Failed to send message after {attempts} attempts: {e}\") raise MessageError(f\"Failed to send message: {e}\") return False","title":"send_message"},{"location":"reference/Client/#neuro_rpc.Client.Client.send_packet","text":"Send a raw packet. Parameters: packet ( bytes ) \u2013 Complete framed packet. Returns: bool \u2013 True if sent successfully. Source code in python/neuro_rpc/Client.py def send_packet(self, packet): \"\"\" Send a raw packet. Args: packet (bytes): Complete framed packet. Returns: bool: True if sent successfully. \"\"\" try: # Send packet self.client.sendall(packet) return True except Exception as e: self.logger.error(f\"Error sending packet: {e}\") return False","title":"send_packet"},{"location":"reference/Client/#neuro_rpc.Client.Client.start","text":"Start the client in a background thread. Notes Spawns a daemon thread that calls connect() and maintains the connection. Source code in python/neuro_rpc/Client.py def start(self): \"\"\" Start the client in a background thread. Notes: Spawns a daemon thread that calls ``connect()`` and maintains the connection. \"\"\" if self.thread_running: self.logger.error(f\"Client is already running in thread {self.client_thread.name}\") return # Start the client in a separate thread def client_thread_func(): try: self.logger.debug(f\"Starting client on thread {threading.current_thread().name}\") self.connect() self.thread_running = True # Main thread loop while self.thread_running: # TODO: handle reconnection logic here time.sleep(0.1) # Prevent CPU hogging except Exception as e: self.logger.error(f\"Client error: {e}\") finally: self.logger.info(\"Client thread terminated\") self.thread_running = False self.client_thread = threading.Thread( target=client_thread_func, name=\"ClientThread\", daemon=True # Make it a daemon so it exits when the main thread exits ) self.client_thread.start() self.logger.debug(\"Client started in background thread\")","title":"start"},{"location":"reference/Client/#neuro_rpc.Client.Client.stop","text":"Stop the client thread and disconnect. Calls disconnect() , stops monitoring, and joins the thread. Source code in python/neuro_rpc/Client.py def stop(self): \"\"\" Stop the client thread and disconnect. Calls ``disconnect()``, stops monitoring, and joins the thread. \"\"\" if not self.thread_running: self.logger.error(\"Client is not running\") return self.logger.info(\"Stopping client...\") try: self.disconnect() # Stop monitor tracker self.handler.tracker.stop_monitoring() # Wait for thread to terminate (with timeout) self.client_thread.join(timeout=2.0) if self.client_thread.is_alive(): self.logger.warning(\"Client thread did not terminate properly\") self.thread_running = False self.logger.info(\"Client stopped\") except Exception as e: self.logger.error(f\"Error stopping client: {e}\")","title":"stop"},{"location":"reference/Client/#neuro_rpc.Client.ConnectionError","text":"Bases: Exception Raised for connection-related errors (e.g., failed connect or lost connection).","title":"ConnectionError"},{"location":"reference/Client/#neuro_rpc.Client.MessageError","text":"Bases: Exception Raised when a message cannot be serialized, sent, or parsed.","title":"MessageError"},{"location":"reference/Client/#neuro_rpc.Client.TimeoutError","text":"Bases: Exception Raised when a receive operation exceeds the configured timeout.","title":"TimeoutError"},{"location":"reference/Console/","text":"Console Interactive console wrapper for NeuroRPC client. Provides a REPL-style interface to manually start, stop, and inspect the state of the TCP client. Useful for debugging and testing RPC connections interactively. Notes Runs with Python's built-in InteractiveConsole. Available commands and modules are preloaded in the interactive namespace. Console(client_config=None) Interactive console for manual client control. Encapsulates startup and shutdown logic for the NeuroRPC client and exposes convenience commands in an interactive REPL environment. Provides status checks and log outputs for debugging. Initialize the interactive console with client configuration. Parameters: client_config ( dict | None , default: None ) \u2013 Optional dictionary of client configuration parameters (host, port, etc.). If None, defaults from Client are used. Source code in python/neuro_rpc/Console.py def __init__(self, client_config=None): \"\"\" Initialize the interactive console with client configuration. Args: client_config (dict | None): Optional dictionary of client configuration parameters (host, port, etc.). If None, defaults from ``Client`` are used. \"\"\" self.client_class = Client self.client_config = client_config or {} self.client = None self.running = False self.logger = Logger.get_logger(self.__class__.__name__) clear_screen() Clear the console screen. Notes Uses OS-specific commands: cls on Windows, clear on Unix-like systems. Source code in python/neuro_rpc/Console.py def clear_screen(self) -> None: \"\"\" Clear the console screen. Notes: Uses OS-specific commands: ``cls`` on Windows, ``clear`` on Unix-like systems. \"\"\" system = platform.system().lower() if system == 'windows': os.system('cls') else: # For Linux, macOS, etc. os.system('clear') client_status() Display current client status in the logger. Shows information about the client object, connection status, active thread, and registered RPC methods (if available). Source code in python/neuro_rpc/Console.py def client_status(self): \"\"\" Display current client status in the logger. Shows information about the client object, connection status, active thread, and registered RPC methods (if available). \"\"\" status = [\"\\n\"] # Check if client object exists if self.client is None: status.append(\"Client not initialized\") status.append(\"To initialize and connect the client, use: start()\") self.logger.error(\"\\n\".join(status)) return # If client exists, check its status status.append(f\"Client object: {type(self.client).__name__}\") status.append(f\"Client connected: {self.client.connected}\") if self.running: status.append(f\"Client thread_running in thread: {self.client.client_thread.name}\") status.append(f\"Thread alive: {self.client.client_thread.is_alive()}\") else: status.append(\"Client not thread_running in background\") # Show handler info if available if hasattr(self.client, 'handler'): handler = self.client.handler if hasattr(handler, 'request_methods'): status.append(f\"Request methods: {list(handler.request_methods.keys())}\") if hasattr(handler, 'response_methods'): status.append(f\"Response methods: {list(handler.response_methods.keys())}\") self.logger.info(\"\\n\".join(status)) run() Run the interactive console. Initializes the interactive console and blocks until exit. Handles Ctrl+C gracefully, stopping the client if necessary. Source code in python/neuro_rpc/Console.py def run(self): \"\"\" Run the interactive console. Initializes the interactive console and blocks until exit. Handles Ctrl+C gracefully, stopping the client if necessary. \"\"\" try: # Start the interactive console immediately self.start_interactive_console() except KeyboardInterrupt: self.logger.error(\"\\nInterrupted by user\") finally: # Make sure to clean up if self.running: self.stop_client() self.logger.info(\"Goodbye!\") start_client() Start the client in a background thread. Notes Instantiates Client if not yet created and calls start() . Source code in python/neuro_rpc/Console.py def start_client(self): \"\"\" Start the client in a background thread. Notes: Instantiates ``Client`` if not yet created and calls ``start()``. \"\"\" # Use existing client instance or create a new one if needed if self.client is None: self.client = self.client_class(**self.client_config) self.client.start() start_interactive_console() Start the REPL console with preloaded commands. Provides start/stop/status/cls commands and access to Logger and LoggerConfig. A banner with usage instructions is displayed at startup. Source code in python/neuro_rpc/Console.py def start_interactive_console(self): \"\"\" Start the REPL console with preloaded commands. Provides start/stop/status/cls commands and access to Logger and LoggerConfig. A banner with usage instructions is displayed at startup. \"\"\" # Prepare the welcome message banner = \"\"\" ================================================================= Message Client Interactive Console ================================================================= The client is not thread_running yet. To start it, use: start() Client object is available as 'client' variable. Once started, use client().method() to interact with the client. Available commands: start() - Start the client in background stop() - Stop the thread_running client status() - Get the status of the client cls() - Clear the console screen Available modules: logger - NeuroRPC logger config_logger - NeuroRPC logger configuration Press Ctrl+D (or Ctrl+Z on Windows) to exit the console. ================================================================= \"\"\" # Prepare the namespace for the console namespace = { 'client': lambda: self.client, 'start': self.start_client, 'stop': self.stop_client, 'status': self.client_status, 'cls': self.clear_screen, 'logger': Logger, 'config_logger': LoggerConfig, } # Create and start the console console = code.InteractiveConsole(locals=namespace) console.interact(banner=banner) # When console exits, make sure to clean up self.logger.info(\"Exiting interactive console...\") if self.running: self.stop_client() stop_client() Stop the running client thread. Notes Calls Client.stop() . Logs error if client is uninitialized. Source code in python/neuro_rpc/Console.py def stop_client(self): \"\"\" Stop the running client thread. Notes: Calls ``Client.stop()``. Logs error if client is uninitialized. \"\"\" if self.client is None: self.logger.error(\"Client object not initialized\") return self.client.stop()","title":"Console"},{"location":"reference/Console/#console","text":"Interactive console wrapper for NeuroRPC client. Provides a REPL-style interface to manually start, stop, and inspect the state of the TCP client. Useful for debugging and testing RPC connections interactively. Notes Runs with Python's built-in InteractiveConsole. Available commands and modules are preloaded in the interactive namespace.","title":"Console"},{"location":"reference/Console/#neuro_rpc.Console.Console","text":"Interactive console for manual client control. Encapsulates startup and shutdown logic for the NeuroRPC client and exposes convenience commands in an interactive REPL environment. Provides status checks and log outputs for debugging. Initialize the interactive console with client configuration. Parameters: client_config ( dict | None , default: None ) \u2013 Optional dictionary of client configuration parameters (host, port, etc.). If None, defaults from Client are used. Source code in python/neuro_rpc/Console.py def __init__(self, client_config=None): \"\"\" Initialize the interactive console with client configuration. Args: client_config (dict | None): Optional dictionary of client configuration parameters (host, port, etc.). If None, defaults from ``Client`` are used. \"\"\" self.client_class = Client self.client_config = client_config or {} self.client = None self.running = False self.logger = Logger.get_logger(self.__class__.__name__)","title":"Console"},{"location":"reference/Console/#neuro_rpc.Console.Console.clear_screen","text":"Clear the console screen. Notes Uses OS-specific commands: cls on Windows, clear on Unix-like systems. Source code in python/neuro_rpc/Console.py def clear_screen(self) -> None: \"\"\" Clear the console screen. Notes: Uses OS-specific commands: ``cls`` on Windows, ``clear`` on Unix-like systems. \"\"\" system = platform.system().lower() if system == 'windows': os.system('cls') else: # For Linux, macOS, etc. os.system('clear')","title":"clear_screen"},{"location":"reference/Console/#neuro_rpc.Console.Console.client_status","text":"Display current client status in the logger. Shows information about the client object, connection status, active thread, and registered RPC methods (if available). Source code in python/neuro_rpc/Console.py def client_status(self): \"\"\" Display current client status in the logger. Shows information about the client object, connection status, active thread, and registered RPC methods (if available). \"\"\" status = [\"\\n\"] # Check if client object exists if self.client is None: status.append(\"Client not initialized\") status.append(\"To initialize and connect the client, use: start()\") self.logger.error(\"\\n\".join(status)) return # If client exists, check its status status.append(f\"Client object: {type(self.client).__name__}\") status.append(f\"Client connected: {self.client.connected}\") if self.running: status.append(f\"Client thread_running in thread: {self.client.client_thread.name}\") status.append(f\"Thread alive: {self.client.client_thread.is_alive()}\") else: status.append(\"Client not thread_running in background\") # Show handler info if available if hasattr(self.client, 'handler'): handler = self.client.handler if hasattr(handler, 'request_methods'): status.append(f\"Request methods: {list(handler.request_methods.keys())}\") if hasattr(handler, 'response_methods'): status.append(f\"Response methods: {list(handler.response_methods.keys())}\") self.logger.info(\"\\n\".join(status))","title":"client_status"},{"location":"reference/Console/#neuro_rpc.Console.Console.run","text":"Run the interactive console. Initializes the interactive console and blocks until exit. Handles Ctrl+C gracefully, stopping the client if necessary. Source code in python/neuro_rpc/Console.py def run(self): \"\"\" Run the interactive console. Initializes the interactive console and blocks until exit. Handles Ctrl+C gracefully, stopping the client if necessary. \"\"\" try: # Start the interactive console immediately self.start_interactive_console() except KeyboardInterrupt: self.logger.error(\"\\nInterrupted by user\") finally: # Make sure to clean up if self.running: self.stop_client() self.logger.info(\"Goodbye!\")","title":"run"},{"location":"reference/Console/#neuro_rpc.Console.Console.start_client","text":"Start the client in a background thread. Notes Instantiates Client if not yet created and calls start() . Source code in python/neuro_rpc/Console.py def start_client(self): \"\"\" Start the client in a background thread. Notes: Instantiates ``Client`` if not yet created and calls ``start()``. \"\"\" # Use existing client instance or create a new one if needed if self.client is None: self.client = self.client_class(**self.client_config) self.client.start()","title":"start_client"},{"location":"reference/Console/#neuro_rpc.Console.Console.start_interactive_console","text":"Start the REPL console with preloaded commands. Provides start/stop/status/cls commands and access to Logger and LoggerConfig. A banner with usage instructions is displayed at startup. Source code in python/neuro_rpc/Console.py def start_interactive_console(self): \"\"\" Start the REPL console with preloaded commands. Provides start/stop/status/cls commands and access to Logger and LoggerConfig. A banner with usage instructions is displayed at startup. \"\"\" # Prepare the welcome message banner = \"\"\" ================================================================= Message Client Interactive Console ================================================================= The client is not thread_running yet. To start it, use: start() Client object is available as 'client' variable. Once started, use client().method() to interact with the client. Available commands: start() - Start the client in background stop() - Stop the thread_running client status() - Get the status of the client cls() - Clear the console screen Available modules: logger - NeuroRPC logger config_logger - NeuroRPC logger configuration Press Ctrl+D (or Ctrl+Z on Windows) to exit the console. ================================================================= \"\"\" # Prepare the namespace for the console namespace = { 'client': lambda: self.client, 'start': self.start_client, 'stop': self.stop_client, 'status': self.client_status, 'cls': self.clear_screen, 'logger': Logger, 'config_logger': LoggerConfig, } # Create and start the console console = code.InteractiveConsole(locals=namespace) console.interact(banner=banner) # When console exits, make sure to clean up self.logger.info(\"Exiting interactive console...\") if self.running: self.stop_client()","title":"start_interactive_console"},{"location":"reference/Console/#neuro_rpc.Console.Console.stop_client","text":"Stop the running client thread. Notes Calls Client.stop() . Logs error if client is uninitialized. Source code in python/neuro_rpc/Console.py def stop_client(self): \"\"\" Stop the running client thread. Notes: Calls ``Client.stop()``. Logs error if client is uninitialized. \"\"\" if self.client is None: self.logger.error(\"Client object not initialized\") return self.client.stop()","title":"stop_client"},{"location":"reference/Logger/","text":"Logger Colorized, structured logging utilities for the NeuroRPC stack. Provides a compact ANSI color formatter and a reusable Logger factory. All modules (Client, Benchmark, RPC stack, Console) use this centralized logging infrastructure to ensure consistent formatting and runtime readability. Notes Uses colorama for cross-platform color handling. Verbosity can be adjusted dynamically. ColoredFormatter Bases: Formatter Minimal ANSI color formatter. Extends logging.Formatter to prepend log messages with ANSI color codes depending on the log level. Colors are reset automatically after each message. format(record) Apply color formatting to a log record. Parameters: record ( LogRecord ) \u2013 Log record object to format. Returns: str \u2013 Formatted string with ANSI colors. Source code in python/neuro_rpc/Logger.py def format(self, record): \"\"\" Apply color formatting to a log record. Args: record (logging.LogRecord): Log record object to format. Returns: str: Formatted string with ANSI colors. \"\"\" msg = super().format(record) color = self.COLORS.get(record.levelno, self.RESET) return f\"{color}{msg}{self.RESET}\" Logger(name, level=logging.DEBUG, verbose=True) Bases: Logger Factory for module-level loggers with a shared format. Ensures all modules share a consistent format and color scheme. Provides caching of Logger instances by name, synchronized levels, and verbosity toggling. Initialize a Logger instance. Parameters: name ( str ) \u2013 Name of the logger. level ( int , default: DEBUG ) \u2013 Log level. verbose ( bool , default: True ) \u2013 Whether verbose format is enabled. Source code in python/neuro_rpc/Logger.py def __init__(self, name: str, level=logging.DEBUG, verbose: bool = True): \"\"\" Initialize a Logger instance. Args: name (str): Name of the logger. level (int): Log level. verbose (bool): Whether verbose format is enabled. \"\"\" super().__init__(name, level) # Set up attributes self.verbose = verbose # Add a StreamHandler import sys self.stream_handler = logging.StreamHandler(sys.stdout) self.addHandler(self.stream_handler) # Set initial levels and formatter self.setLevel(level) self._set_formatter() get_logger(name='__neuro__', level=logging.DEBUG, verbose=True) staticmethod Get or create a configured logger. Parameters: name ( str , default: '__neuro__' ) \u2013 Logger identifier (typically module or class name). level ( int , default: DEBUG ) \u2013 Log level (default DEBUG ). verbose ( bool , default: True ) \u2013 Whether to include extended context (process/thread info). Returns: Logger \u2013 Configured logger instance. Notes Attaches a StreamHandler on first creation. Source code in python/neuro_rpc/Logger.py @staticmethod def get_logger(name=\"__neuro__\", level=logging.DEBUG, verbose=True): \"\"\" Get or create a configured logger. Args: name (str): Logger identifier (typically module or class name). level (int): Log level (default ``DEBUG``). verbose (bool): Whether to include extended context (process/thread info). Returns: Logger: Configured logger instance. Notes: Attaches a StreamHandler on first creation. \"\"\" if name not in Logger._instances: Logger._instances[name] = Logger(name, level, verbose) return Logger._instances[name] print_loggers() staticmethod Print currently registered loggers. Useful for debugging which loggers are active and their configuration. Source code in python/neuro_rpc/Logger.py @staticmethod def print_loggers(): \"\"\" Print currently registered loggers. Useful for debugging which loggers are active and their configuration. \"\"\" for name, logger in Logger._instances.items(): print(f\"{name}: {logger} {logger.handlers} {logger.level}\") setLevel(level) Override setLevel to synchronize handler level. Parameters: level ( int ) \u2013 New log level. Source code in python/neuro_rpc/Logger.py def setLevel(self, level) -> None: \"\"\" Override setLevel to synchronize handler level. Args: level (int): New log level. \"\"\" super().setLevel(level) self.stream_handler.setLevel(level) # Ensure handler level matches logger level setVerbose(verbose) Dynamically update verbosity and re-apply formatter. Parameters: verbose ( bool ) \u2013 True for detailed context, False for compact output. Source code in python/neuro_rpc/Logger.py def setVerbose(self, verbose: bool) -> None: \"\"\" Dynamically update verbosity and re-apply formatter. Args: verbose (bool): True for detailed context, False for compact output. \"\"\" self.verbose = verbose self._set_formatter() test() Emit test messages at all levels. Useful for verifying logger color and format configuration. Source code in python/neuro_rpc/Logger.py def test(self) -> None: \"\"\" Emit test messages at all levels. Useful for verifying logger color and format configuration. \"\"\" self.debug(\"This is a DEBUG message.\") self.info(\"This is an INFO message.\") self.warning(\"This is a WARNING message.\") self.error(\"This is an ERROR message.\") self.critical(\"This is a CRITICAL message.\") LoggerConfig Default logging configuration holder. Provides presets for production, development, and per-component debugging. configure_for_debugging(component_name, level=logging.DEBUG, verbose=True) staticmethod Configure a specific component for debugging. Parameters: component_name ( str ) \u2013 Name of the component/logger. level ( int , default: DEBUG ) \u2013 Log level (default DEBUG ). verbose ( bool , default: True ) \u2013 Verbosity flag. Notes Creates a new logger if not already registered. Source code in python/neuro_rpc/Logger.py @staticmethod def configure_for_debugging(component_name, level=logging.DEBUG, verbose=True): \"\"\" Configure a specific component for debugging. Args: component_name (str): Name of the component/logger. level (int): Log level (default ``DEBUG``). verbose (bool): Verbosity flag. Notes: Creates a new logger if not already registered. \"\"\" if component_name in Logger._instances: Logger._instances[component_name].setLevel(level) Logger._instances[component_name].setVerbose(verbose) else: Logger.get_logger(component_name, level, verbose) Logger._instances[component_name].warning(f\"Logger '{component_name}' not found. Creating a new one.\") configure_for_development() staticmethod Configure all loggers for development. Sets DEBUG level and enables verbose formatting. Source code in python/neuro_rpc/Logger.py @staticmethod def configure_for_development(): \"\"\" Configure all loggers for development. Sets ``DEBUG`` level and enables verbose formatting. \"\"\" for name, logger_instance in Logger._instances.items(): logger_instance.setLevel(logging.DEBUG) logger_instance.setVerbose(True) configure_for_production() staticmethod Configure all loggers for production. Sets INFO level and disables verbose formatting. Source code in python/neuro_rpc/Logger.py @staticmethod def configure_for_production(): \"\"\" Configure all loggers for production. Sets ``INFO`` level and disables verbose formatting. \"\"\" for name, logger_instance in Logger._instances.items(): logger_instance.setLevel(logging.INFO) logger_instance.setVerbose(False)","title":"Logger"},{"location":"reference/Logger/#logger","text":"Colorized, structured logging utilities for the NeuroRPC stack. Provides a compact ANSI color formatter and a reusable Logger factory. All modules (Client, Benchmark, RPC stack, Console) use this centralized logging infrastructure to ensure consistent formatting and runtime readability. Notes Uses colorama for cross-platform color handling. Verbosity can be adjusted dynamically.","title":"Logger"},{"location":"reference/Logger/#neuro_rpc.Logger.ColoredFormatter","text":"Bases: Formatter Minimal ANSI color formatter. Extends logging.Formatter to prepend log messages with ANSI color codes depending on the log level. Colors are reset automatically after each message.","title":"ColoredFormatter"},{"location":"reference/Logger/#neuro_rpc.Logger.ColoredFormatter.format","text":"Apply color formatting to a log record. Parameters: record ( LogRecord ) \u2013 Log record object to format. Returns: str \u2013 Formatted string with ANSI colors. Source code in python/neuro_rpc/Logger.py def format(self, record): \"\"\" Apply color formatting to a log record. Args: record (logging.LogRecord): Log record object to format. Returns: str: Formatted string with ANSI colors. \"\"\" msg = super().format(record) color = self.COLORS.get(record.levelno, self.RESET) return f\"{color}{msg}{self.RESET}\"","title":"format"},{"location":"reference/Logger/#neuro_rpc.Logger.Logger","text":"Bases: Logger Factory for module-level loggers with a shared format. Ensures all modules share a consistent format and color scheme. Provides caching of Logger instances by name, synchronized levels, and verbosity toggling. Initialize a Logger instance. Parameters: name ( str ) \u2013 Name of the logger. level ( int , default: DEBUG ) \u2013 Log level. verbose ( bool , default: True ) \u2013 Whether verbose format is enabled. Source code in python/neuro_rpc/Logger.py def __init__(self, name: str, level=logging.DEBUG, verbose: bool = True): \"\"\" Initialize a Logger instance. Args: name (str): Name of the logger. level (int): Log level. verbose (bool): Whether verbose format is enabled. \"\"\" super().__init__(name, level) # Set up attributes self.verbose = verbose # Add a StreamHandler import sys self.stream_handler = logging.StreamHandler(sys.stdout) self.addHandler(self.stream_handler) # Set initial levels and formatter self.setLevel(level) self._set_formatter()","title":"Logger"},{"location":"reference/Logger/#neuro_rpc.Logger.Logger.get_logger","text":"Get or create a configured logger. Parameters: name ( str , default: '__neuro__' ) \u2013 Logger identifier (typically module or class name). level ( int , default: DEBUG ) \u2013 Log level (default DEBUG ). verbose ( bool , default: True ) \u2013 Whether to include extended context (process/thread info). Returns: Logger \u2013 Configured logger instance. Notes Attaches a StreamHandler on first creation. Source code in python/neuro_rpc/Logger.py @staticmethod def get_logger(name=\"__neuro__\", level=logging.DEBUG, verbose=True): \"\"\" Get or create a configured logger. Args: name (str): Logger identifier (typically module or class name). level (int): Log level (default ``DEBUG``). verbose (bool): Whether to include extended context (process/thread info). Returns: Logger: Configured logger instance. Notes: Attaches a StreamHandler on first creation. \"\"\" if name not in Logger._instances: Logger._instances[name] = Logger(name, level, verbose) return Logger._instances[name]","title":"get_logger"},{"location":"reference/Logger/#neuro_rpc.Logger.Logger.print_loggers","text":"Print currently registered loggers. Useful for debugging which loggers are active and their configuration. Source code in python/neuro_rpc/Logger.py @staticmethod def print_loggers(): \"\"\" Print currently registered loggers. Useful for debugging which loggers are active and their configuration. \"\"\" for name, logger in Logger._instances.items(): print(f\"{name}: {logger} {logger.handlers} {logger.level}\")","title":"print_loggers"},{"location":"reference/Logger/#neuro_rpc.Logger.Logger.setLevel","text":"Override setLevel to synchronize handler level. Parameters: level ( int ) \u2013 New log level. Source code in python/neuro_rpc/Logger.py def setLevel(self, level) -> None: \"\"\" Override setLevel to synchronize handler level. Args: level (int): New log level. \"\"\" super().setLevel(level) self.stream_handler.setLevel(level) # Ensure handler level matches logger level","title":"setLevel"},{"location":"reference/Logger/#neuro_rpc.Logger.Logger.setVerbose","text":"Dynamically update verbosity and re-apply formatter. Parameters: verbose ( bool ) \u2013 True for detailed context, False for compact output. Source code in python/neuro_rpc/Logger.py def setVerbose(self, verbose: bool) -> None: \"\"\" Dynamically update verbosity and re-apply formatter. Args: verbose (bool): True for detailed context, False for compact output. \"\"\" self.verbose = verbose self._set_formatter()","title":"setVerbose"},{"location":"reference/Logger/#neuro_rpc.Logger.Logger.test","text":"Emit test messages at all levels. Useful for verifying logger color and format configuration. Source code in python/neuro_rpc/Logger.py def test(self) -> None: \"\"\" Emit test messages at all levels. Useful for verifying logger color and format configuration. \"\"\" self.debug(\"This is a DEBUG message.\") self.info(\"This is an INFO message.\") self.warning(\"This is a WARNING message.\") self.error(\"This is an ERROR message.\") self.critical(\"This is a CRITICAL message.\")","title":"test"},{"location":"reference/Logger/#neuro_rpc.Logger.LoggerConfig","text":"Default logging configuration holder. Provides presets for production, development, and per-component debugging.","title":"LoggerConfig"},{"location":"reference/Logger/#neuro_rpc.Logger.LoggerConfig.configure_for_debugging","text":"Configure a specific component for debugging. Parameters: component_name ( str ) \u2013 Name of the component/logger. level ( int , default: DEBUG ) \u2013 Log level (default DEBUG ). verbose ( bool , default: True ) \u2013 Verbosity flag. Notes Creates a new logger if not already registered. Source code in python/neuro_rpc/Logger.py @staticmethod def configure_for_debugging(component_name, level=logging.DEBUG, verbose=True): \"\"\" Configure a specific component for debugging. Args: component_name (str): Name of the component/logger. level (int): Log level (default ``DEBUG``). verbose (bool): Verbosity flag. Notes: Creates a new logger if not already registered. \"\"\" if component_name in Logger._instances: Logger._instances[component_name].setLevel(level) Logger._instances[component_name].setVerbose(verbose) else: Logger.get_logger(component_name, level, verbose) Logger._instances[component_name].warning(f\"Logger '{component_name}' not found. Creating a new one.\")","title":"configure_for_debugging"},{"location":"reference/Logger/#neuro_rpc.Logger.LoggerConfig.configure_for_development","text":"Configure all loggers for development. Sets DEBUG level and enables verbose formatting. Source code in python/neuro_rpc/Logger.py @staticmethod def configure_for_development(): \"\"\" Configure all loggers for development. Sets ``DEBUG`` level and enables verbose formatting. \"\"\" for name, logger_instance in Logger._instances.items(): logger_instance.setLevel(logging.DEBUG) logger_instance.setVerbose(True)","title":"configure_for_development"},{"location":"reference/Logger/#neuro_rpc.Logger.LoggerConfig.configure_for_production","text":"Configure all loggers for production. Sets INFO level and disables verbose formatting. Source code in python/neuro_rpc/Logger.py @staticmethod def configure_for_production(): \"\"\" Configure all loggers for production. Sets ``INFO`` level and disables verbose formatting. \"\"\" for name, logger_instance in Logger._instances.items(): logger_instance.setLevel(logging.INFO) logger_instance.setVerbose(False)","title":"configure_for_production"},{"location":"reference/Proxy/","text":"Proxy Conversion utilities between Python dictionaries/tuples and LabVIEW Clusters. Provides serialization and deserialization helpers to encode/decode nested data structures into LabVIEW's Cluster representation. Also integrates with RPCRequest/RPCResponse to support actor-style communication with LabVIEW classes. Notes Extends ClusterConverter from python.labview_data.type_converters . NpEncoder Bases: JSONEncoder JSON encoder for NumPy data types. Converts numpy.integer , numpy.floating , and numpy.ndarray into standard Python int , float , and list for JSON serialization compatibility. default(obj) Override JSON encoding for NumPy objects. Parameters: obj ( Any ) \u2013 Object to encode. Returns: Any \u2013 Encoded Python-native type. Source code in python/neuro_rpc/Proxy.py def default(self, obj): \"\"\" Override JSON encoding for NumPy objects. Args: obj (Any): Object to encode. Returns: Any: Encoded Python-native type. \"\"\" if isinstance(obj, np.integer): return int(obj) if isinstance(obj, np.floating): return float(obj) if isinstance(obj, np.ndarray): return obj.tolist() return super().default(obj) Proxy Bases: ClusterConverter Proxy class to convert between Python dicts and LabVIEW Cluster bytes. Implements bidirectional mapping of nested dict/tuple structures to LabVIEW Cluster format, supporting serialization for sending RPC requests and deserialization of responses. dict_to_tuple(d) Convert a dictionary into a (values, keys) tuple. Recursively descends into nested dictionaries to preserve structure. Parameters: d ( dict ) \u2013 Input dictionary. Returns: tuple [ list , list ] \u2013 tuple[list, list]: (values, keys) representation of the dictionary. Source code in python/neuro_rpc/Proxy.py def dict_to_tuple(self, d: dict) -> tuple[list, list]: \"\"\" Convert a dictionary into a (values, keys) tuple. Recursively descends into nested dictionaries to preserve structure. Args: d (dict): Input dictionary. Returns: tuple[list, list]: (values, keys) representation of the dictionary. \"\"\" keys = list(d.keys()) values = [] for k in keys: v = d[k] if isinstance(v, dict): v = self.dict_to_tuple(v) values.append(v) return values, keys from_act(raw_bytes, hdr_tree) Convert LabVIEW Actor Cluster bytes back into an RPCResponse. Parameters: raw_bytes ( bytes ) \u2013 Cluster flat buffer. hdr_tree ( dict ) \u2013 Metadata tree from serialization. Returns: dict \u2013 RPCResponse serialized as dictionary. Source code in python/neuro_rpc/Proxy.py def from_act(self, raw_bytes: bytes, hdr_tree: dict): \"\"\" Convert LabVIEW Actor Cluster bytes back into an RPCResponse. Args: raw_bytes (bytes): Cluster flat buffer. hdr_tree (dict): Metadata tree from serialization. Returns: dict: RPCResponse serialized as dictionary. \"\"\" recovered_vals, recovered_keys = self.from_cluster_bytes_and_tree(raw_bytes, hdr_tree) dict_ = self.tuple_to_dict((recovered_vals, recovered_keys)) id = dict_[\"Data\"].pop(\"id\") return RPCResponse(id=id, result=dict_[\"Data\"]).to_dict() from_cluster_bytes_and_tree(raw_bytes, hdr_tree, sdata=None, encoding='ansi') Reconstruct a (values, keys) tuple from Cluster bytes and metadata tree. Parameters: raw_bytes ( bytes ) \u2013 Flat buffer for the cluster. hdr_tree ( dict ) \u2013 Metadata tree including headers, keys, and children. sdata ( SerializationData , default: None ) \u2013 Deserialization context. encoding ( str , default: 'ansi' ) \u2013 Encoding used for string payloads. Defaults to \"ansi\". Returns: tuple [ list , list ] \u2013 tuple[list, list]: (values, keys) structure. Source code in python/neuro_rpc/Proxy.py def from_cluster_bytes_and_tree( self, raw_bytes: bytes, hdr_tree: dict, sdata: SerializationData = None, encoding: str = \"ansi\" ) -> tuple[list, list]: \"\"\" Reconstruct a (values, keys) tuple from Cluster bytes and metadata tree. Args: raw_bytes (bytes): Flat buffer for the cluster. hdr_tree (dict): Metadata tree including headers, keys, and children. sdata (SerializationData, optional): Deserialization context. encoding (str): Encoding used for string payloads. Defaults to \"ansi\". Returns: tuple[list, list]: (values, keys) structure. \"\"\" if sdata is None: sdata = SerializationData(version=0) full = hdr_tree[\"header\"] + raw_bytes hi = HeaderInfo.parse(full, offset_h=0) dd = DeserializationData( header=hi, buffer=full, offset_d=hi.end, version=sdata.version ) vals = list(ClusterConverter.deserialize(dd).value) keys = hdr_tree[\"keys\"] for child in hdr_tree.get(\"children\", []): idx = child[\"index\"] sub_tree = child[\"tree\"] buf_sub = vals[idx].encode(encoding) vals[idx] = self.from_cluster_bytes_and_tree(buf_sub, sub_tree, sdata, encoding) return vals, keys to_act(Message) Convert an RPCRequest/Message dict into a LabVIEW Actor Cluster. Parameters: Message ( dict | RPCRequest ) \u2013 Message to encode. Returns: \u2013 tuple[bytes, dict]: (flat buffer, metadata tree). Source code in python/neuro_rpc/Proxy.py def to_act(self, Message): \"\"\" Convert an RPCRequest/Message dict into a LabVIEW Actor Cluster. Args: Message (dict | RPCRequest): Message to encode. Returns: tuple[bytes, dict]: (flat buffer, metadata tree). \"\"\" if isinstance(Message, RPCRequest): Message = Message.to_dict() id = Message.pop(\"id\") Message[\"params\"] = {\"id\": id, **Message[\"params\"]} self.Actor[\"Class name\"] = f\"Chat Window.lvlib:{Message['method']} Msg.lvclass\" self.Actor[\"Data\"] = { \"Message\": Message[\"params\"][\"Message\"], \"id\": Message[\"params\"][\"id\"], \"exec_time\": np.int32(0) } tupla = self.dict_to_tuple(self.Actor) self.to_cluster_bytes_with_tree(tupla) return self.to_cluster_bytes_with_tree(tupla) to_cluster_bytes_with_tree(tup, sdata=None, encoding='ansi') Serialize a (values, keys) tuple into a LabVIEW Cluster flat buffer. Parameters: tup ( tuple [ list , list ] ) \u2013 (values, keys) representation of the cluster. sdata ( SerializationData , default: None ) \u2013 Serialization metadata. Defaults to version=0. encoding ( str , default: 'ansi' ) \u2013 Encoding to use for nested buffers. Defaults to \"ansi\". Returns: tuple [ bytes , dict ] \u2013 tuple[bytes, dict]: (flat buffer, metadata tree). Source code in python/neuro_rpc/Proxy.py def to_cluster_bytes_with_tree( self, tup: tuple[list, list], sdata: SerializationData = None, encoding: str = \"ansi\" ) -> tuple[bytes, dict]: \"\"\" Serialize a (values, keys) tuple into a LabVIEW Cluster flat buffer. Args: tup (tuple[list, list]): (values, keys) representation of the cluster. sdata (SerializationData, optional): Serialization metadata. Defaults to version=0. encoding (str): Encoding to use for nested buffers. Defaults to \"ansi\". Returns: tuple[bytes, dict]: (flat buffer, metadata tree). \"\"\" if sdata is None: sdata = SerializationData(version=0) values, keys = tup processed = [] children = [] for idx, v in enumerate(values): if isinstance(v, tuple): buf_str, subtree = self.to_cluster_bytes_with_tree(v, sdata, encoding) processed.append(buf_str.decode(encoding)) children.append({ \"index\": idx, \"keys\": v[1], \"tree\": subtree }) else: processed.append(v) cluster = Cluster(processed, keys) res = ClusterConverter.serialize(cluster, sdata) return ( res.flat_buffer(), { \"header\": res.flat_header(), \"keys\": keys, \"children\": children } ) tuple_to_dict(values_keys) Convert a (values, keys) tuple back into a dictionary. Recursively reconstructs nested dictionaries from tuple representations. Parameters: values_keys ( tuple [ list , list ] ) \u2013 (values, keys) pair. Returns: dict ( dict ) \u2013 Reconstructed dictionary. Source code in python/neuro_rpc/Proxy.py def tuple_to_dict(self, values_keys) -> dict: \"\"\" Convert a (values, keys) tuple back into a dictionary. Recursively reconstructs nested dictionaries from tuple representations. Args: values_keys (tuple[list, list]): (values, keys) pair. Returns: dict: Reconstructed dictionary. \"\"\" values, keys = values_keys result = {} for key, val in zip(keys, values): if ( isinstance(val, tuple) and len(val) == 2 and isinstance(val[0], list) and isinstance(val[1], list) ): result[key] = self.tuple_to_dict(val) else: result[key] = val return result","title":"Proxy"},{"location":"reference/Proxy/#proxy","text":"Conversion utilities between Python dictionaries/tuples and LabVIEW Clusters. Provides serialization and deserialization helpers to encode/decode nested data structures into LabVIEW's Cluster representation. Also integrates with RPCRequest/RPCResponse to support actor-style communication with LabVIEW classes. Notes Extends ClusterConverter from python.labview_data.type_converters .","title":"Proxy"},{"location":"reference/Proxy/#neuro_rpc.Proxy.NpEncoder","text":"Bases: JSONEncoder JSON encoder for NumPy data types. Converts numpy.integer , numpy.floating , and numpy.ndarray into standard Python int , float , and list for JSON serialization compatibility.","title":"NpEncoder"},{"location":"reference/Proxy/#neuro_rpc.Proxy.NpEncoder.default","text":"Override JSON encoding for NumPy objects. Parameters: obj ( Any ) \u2013 Object to encode. Returns: Any \u2013 Encoded Python-native type. Source code in python/neuro_rpc/Proxy.py def default(self, obj): \"\"\" Override JSON encoding for NumPy objects. Args: obj (Any): Object to encode. Returns: Any: Encoded Python-native type. \"\"\" if isinstance(obj, np.integer): return int(obj) if isinstance(obj, np.floating): return float(obj) if isinstance(obj, np.ndarray): return obj.tolist() return super().default(obj)","title":"default"},{"location":"reference/Proxy/#neuro_rpc.Proxy.Proxy","text":"Bases: ClusterConverter Proxy class to convert between Python dicts and LabVIEW Cluster bytes. Implements bidirectional mapping of nested dict/tuple structures to LabVIEW Cluster format, supporting serialization for sending RPC requests and deserialization of responses.","title":"Proxy"},{"location":"reference/Proxy/#neuro_rpc.Proxy.Proxy.dict_to_tuple","text":"Convert a dictionary into a (values, keys) tuple. Recursively descends into nested dictionaries to preserve structure. Parameters: d ( dict ) \u2013 Input dictionary. Returns: tuple [ list , list ] \u2013 tuple[list, list]: (values, keys) representation of the dictionary. Source code in python/neuro_rpc/Proxy.py def dict_to_tuple(self, d: dict) -> tuple[list, list]: \"\"\" Convert a dictionary into a (values, keys) tuple. Recursively descends into nested dictionaries to preserve structure. Args: d (dict): Input dictionary. Returns: tuple[list, list]: (values, keys) representation of the dictionary. \"\"\" keys = list(d.keys()) values = [] for k in keys: v = d[k] if isinstance(v, dict): v = self.dict_to_tuple(v) values.append(v) return values, keys","title":"dict_to_tuple"},{"location":"reference/Proxy/#neuro_rpc.Proxy.Proxy.from_act","text":"Convert LabVIEW Actor Cluster bytes back into an RPCResponse. Parameters: raw_bytes ( bytes ) \u2013 Cluster flat buffer. hdr_tree ( dict ) \u2013 Metadata tree from serialization. Returns: dict \u2013 RPCResponse serialized as dictionary. Source code in python/neuro_rpc/Proxy.py def from_act(self, raw_bytes: bytes, hdr_tree: dict): \"\"\" Convert LabVIEW Actor Cluster bytes back into an RPCResponse. Args: raw_bytes (bytes): Cluster flat buffer. hdr_tree (dict): Metadata tree from serialization. Returns: dict: RPCResponse serialized as dictionary. \"\"\" recovered_vals, recovered_keys = self.from_cluster_bytes_and_tree(raw_bytes, hdr_tree) dict_ = self.tuple_to_dict((recovered_vals, recovered_keys)) id = dict_[\"Data\"].pop(\"id\") return RPCResponse(id=id, result=dict_[\"Data\"]).to_dict()","title":"from_act"},{"location":"reference/Proxy/#neuro_rpc.Proxy.Proxy.from_cluster_bytes_and_tree","text":"Reconstruct a (values, keys) tuple from Cluster bytes and metadata tree. Parameters: raw_bytes ( bytes ) \u2013 Flat buffer for the cluster. hdr_tree ( dict ) \u2013 Metadata tree including headers, keys, and children. sdata ( SerializationData , default: None ) \u2013 Deserialization context. encoding ( str , default: 'ansi' ) \u2013 Encoding used for string payloads. Defaults to \"ansi\". Returns: tuple [ list , list ] \u2013 tuple[list, list]: (values, keys) structure. Source code in python/neuro_rpc/Proxy.py def from_cluster_bytes_and_tree( self, raw_bytes: bytes, hdr_tree: dict, sdata: SerializationData = None, encoding: str = \"ansi\" ) -> tuple[list, list]: \"\"\" Reconstruct a (values, keys) tuple from Cluster bytes and metadata tree. Args: raw_bytes (bytes): Flat buffer for the cluster. hdr_tree (dict): Metadata tree including headers, keys, and children. sdata (SerializationData, optional): Deserialization context. encoding (str): Encoding used for string payloads. Defaults to \"ansi\". Returns: tuple[list, list]: (values, keys) structure. \"\"\" if sdata is None: sdata = SerializationData(version=0) full = hdr_tree[\"header\"] + raw_bytes hi = HeaderInfo.parse(full, offset_h=0) dd = DeserializationData( header=hi, buffer=full, offset_d=hi.end, version=sdata.version ) vals = list(ClusterConverter.deserialize(dd).value) keys = hdr_tree[\"keys\"] for child in hdr_tree.get(\"children\", []): idx = child[\"index\"] sub_tree = child[\"tree\"] buf_sub = vals[idx].encode(encoding) vals[idx] = self.from_cluster_bytes_and_tree(buf_sub, sub_tree, sdata, encoding) return vals, keys","title":"from_cluster_bytes_and_tree"},{"location":"reference/Proxy/#neuro_rpc.Proxy.Proxy.to_act","text":"Convert an RPCRequest/Message dict into a LabVIEW Actor Cluster. Parameters: Message ( dict | RPCRequest ) \u2013 Message to encode. Returns: \u2013 tuple[bytes, dict]: (flat buffer, metadata tree). Source code in python/neuro_rpc/Proxy.py def to_act(self, Message): \"\"\" Convert an RPCRequest/Message dict into a LabVIEW Actor Cluster. Args: Message (dict | RPCRequest): Message to encode. Returns: tuple[bytes, dict]: (flat buffer, metadata tree). \"\"\" if isinstance(Message, RPCRequest): Message = Message.to_dict() id = Message.pop(\"id\") Message[\"params\"] = {\"id\": id, **Message[\"params\"]} self.Actor[\"Class name\"] = f\"Chat Window.lvlib:{Message['method']} Msg.lvclass\" self.Actor[\"Data\"] = { \"Message\": Message[\"params\"][\"Message\"], \"id\": Message[\"params\"][\"id\"], \"exec_time\": np.int32(0) } tupla = self.dict_to_tuple(self.Actor) self.to_cluster_bytes_with_tree(tupla) return self.to_cluster_bytes_with_tree(tupla)","title":"to_act"},{"location":"reference/Proxy/#neuro_rpc.Proxy.Proxy.to_cluster_bytes_with_tree","text":"Serialize a (values, keys) tuple into a LabVIEW Cluster flat buffer. Parameters: tup ( tuple [ list , list ] ) \u2013 (values, keys) representation of the cluster. sdata ( SerializationData , default: None ) \u2013 Serialization metadata. Defaults to version=0. encoding ( str , default: 'ansi' ) \u2013 Encoding to use for nested buffers. Defaults to \"ansi\". Returns: tuple [ bytes , dict ] \u2013 tuple[bytes, dict]: (flat buffer, metadata tree). Source code in python/neuro_rpc/Proxy.py def to_cluster_bytes_with_tree( self, tup: tuple[list, list], sdata: SerializationData = None, encoding: str = \"ansi\" ) -> tuple[bytes, dict]: \"\"\" Serialize a (values, keys) tuple into a LabVIEW Cluster flat buffer. Args: tup (tuple[list, list]): (values, keys) representation of the cluster. sdata (SerializationData, optional): Serialization metadata. Defaults to version=0. encoding (str): Encoding to use for nested buffers. Defaults to \"ansi\". Returns: tuple[bytes, dict]: (flat buffer, metadata tree). \"\"\" if sdata is None: sdata = SerializationData(version=0) values, keys = tup processed = [] children = [] for idx, v in enumerate(values): if isinstance(v, tuple): buf_str, subtree = self.to_cluster_bytes_with_tree(v, sdata, encoding) processed.append(buf_str.decode(encoding)) children.append({ \"index\": idx, \"keys\": v[1], \"tree\": subtree }) else: processed.append(v) cluster = Cluster(processed, keys) res = ClusterConverter.serialize(cluster, sdata) return ( res.flat_buffer(), { \"header\": res.flat_header(), \"keys\": keys, \"children\": children } )","title":"to_cluster_bytes_with_tree"},{"location":"reference/Proxy/#neuro_rpc.Proxy.Proxy.tuple_to_dict","text":"Convert a (values, keys) tuple back into a dictionary. Recursively reconstructs nested dictionaries from tuple representations. Parameters: values_keys ( tuple [ list , list ] ) \u2013 (values, keys) pair. Returns: dict ( dict ) \u2013 Reconstructed dictionary. Source code in python/neuro_rpc/Proxy.py def tuple_to_dict(self, values_keys) -> dict: \"\"\" Convert a (values, keys) tuple back into a dictionary. Recursively reconstructs nested dictionaries from tuple representations. Args: values_keys (tuple[list, list]): (values, keys) pair. Returns: dict: Reconstructed dictionary. \"\"\" values, keys = values_keys result = {} for key, val in zip(keys, values): if ( isinstance(val, tuple) and len(val) == 2 and isinstance(val[0], list) and isinstance(val[1], list) ): result[key] = self.tuple_to_dict(val) else: result[key] = val return result","title":"tuple_to_dict"},{"location":"reference/RPCHandler/","text":"RPCHandler Registration and dispatch of RPC request/response methods. Implements a handler for JSON-Message 2.0 (similar to JSON-RPC 2.0), providing: - Method registration via the @rpc_method decorator. - Creation of request, response, and error messages. - Processing of incoming messages (both requests and responses). - Integration with Benchmark to track latency and round-trip times. Notes Acts as the bridge between raw JSON messages and Python method calls. RPCHandler() Bases: RPCMessage Core handler for JSON-Message 2.0 operations. Manages registration of request/response handlers, creation of message objects, and routing of incoming messages. Integrates with Benchmark to track requests and responses. Initialize the RPCHandler. Creates registries for request/response methods, sets up a Benchmark tracker, and initializes a logger. Source code in python/neuro_rpc/RPCHandler.py def __init__(self): \"\"\" Initialize the RPCHandler. Creates registries for request/response methods, sets up a Benchmark tracker, and initializes a logger. \"\"\" super().__init__() self.request_methods: Dict[str, Callable] = {} self.response_methods: Dict[str, Callable] = {} self._request_id = 0 self.tracker = Benchmark() self.logger = Logger.get_logger(self.__class__.__name__) create_error(error_type, data=None, id=None) Create a JSON-Message error object. Parameters: error_type ( str | dict ) \u2013 Error type (see RPCError constants). data ( Any , default: None ) \u2013 Additional error details. id ( str , default: None ) \u2013 ID of the related request. Returns: dict \u2013 Serialized error response object. Source code in python/neuro_rpc/RPCHandler.py def create_error(self, error_type, data=None, id=None): \"\"\" Create a JSON-Message error object. Args: error_type (str | dict): Error type (see RPCError constants). data (Any, optional): Additional error details. id (str, optional): ID of the related request. Returns: dict: Serialized error response object. \"\"\" error = RPCError(error_type=error_type, data=data) response = RPCResponse(error=error.error, id=id) if self.tracker: self.tracker.track_outgoing_response(response) return response.to_dict() create_request(method, params=None, request_id=None) Create a JSON-Message request object. Parameters: method ( str ) \u2013 Method name to call. params ( dict | list , default: None ) \u2013 Parameters for the request. request_id ( str , default: None ) \u2013 Custom request ID (UUID by default). Returns: dict \u2013 Serialized request object. Source code in python/neuro_rpc/RPCHandler.py def create_request(self, method, params=None, request_id=None): \"\"\" Create a JSON-Message request object. Args: method (str): Method name to call. params (dict | list, optional): Parameters for the request. request_id (str, optional): Custom request ID (UUID by default). Returns: dict: Serialized request object. \"\"\" if request_id is None: request_id = str(uuid.uuid4()) request = RPCRequest(method=method, id=request_id, params=params) request_dict = request.to_dict() if self.tracker: self.tracker.track_outgoing_request(request) return request_dict create_response(result, request_id) Create a JSON-Message response object. Parameters: result ( Any ) \u2013 The result to return. request_id ( str ) \u2013 ID of the original request. Returns: dict \u2013 Serialized response object. Source code in python/neuro_rpc/RPCHandler.py def create_response(self, result, request_id): \"\"\" Create a JSON-Message response object. Args: result (Any): The result to return. request_id (str): ID of the original request. Returns: dict: Serialized response object. \"\"\" response = RPCResponse(result=result, id=request_id) response_dict = response.to_dict() if self.tracker: self.tracker.track_outgoing_response(response) return response_dict next_request_id() Generate a new request ID. Returns: int ( int ) \u2013 Incremental request ID. Source code in python/neuro_rpc/RPCHandler.py def next_request_id(self) -> int: \"\"\" Generate a new request ID. Returns: int: Incremental request ID. \"\"\" self._request_id += 1 return self._request_id process_message(message) Process an incoming JSON-Message. Parses input (string/dict/RPCMessage), converts to RPCRequest or RPCResponse, and dispatches to the appropriate handler. Parameters: message ( dict | str | RPCMessage ) \u2013 Incoming message. Returns: Optional [ Dict [ str , Any ]] \u2013 dict | None: Response dict if request, None if response. Raises: RPCError \u2013 If message is invalid or cannot be parsed. Source code in python/neuro_rpc/RPCHandler.py def process_message(self, message: Union[Dict[str, Any], str, RPCMessage]) -> Optional[Dict[str, Any]]: \"\"\" Process an incoming JSON-Message. Parses input (string/dict/RPCMessage), converts to RPCRequest or RPCResponse, and dispatches to the appropriate handler. Args: message (dict | str | RPCMessage): Incoming message. Returns: dict | None: Response dict if request, None if response. Raises: RPCError: If message is invalid or cannot be parsed. \"\"\" try: if isinstance(message, str): try: import json message = json.loads(message) except Exception as e: self.logger.error(f\"JSON parse error: {e}\") return self.create_error(RPCError.PARSE_ERROR) if isinstance(message, dict): if \"method\" in message: try: rpc_message = RPCRequest.from_dict(message) except Exception: return self.create_error(RPCError.INVALID_REQUEST) elif \"result\" in message or \"error\" in message: try: rpc_message = RPCResponse.from_dict(message) except Exception: return self.create_error(RPCError.INVALID_REQUEST) else: return self.create_error(RPCError.INVALID_REQUEST) else: return self.create_error(RPCError.INVALID_REQUEST) if isinstance(rpc_message, RPCRequest): return self._process_request(rpc_message) elif isinstance(rpc_message, RPCResponse): self._process_response(rpc_message) return None else: return self.create_error(RPCError.INVALID_REQUEST) except Exception as e: self.logger.error(f\"Error processing message: {e}\", exc_info=True) return self.create_error(RPCError.INTERNAL_ERROR, data=str(e)) register_methods(instance) Register decorated methods from an instance. Scans instance methods and registers those annotated with @rpc_method . Parameters: instance ( Any ) \u2013 Object instance containing decorated methods. Source code in python/neuro_rpc/RPCHandler.py def register_methods(self, instance) -> None: \"\"\" Register decorated methods from an instance. Scans instance methods and registers those annotated with ``@rpc_method``. Args: instance (Any): Object instance containing decorated methods. \"\"\" for name, method in inspect.getmembers(instance, predicate=inspect.ismethod): if hasattr(method, \"_is_rpc_method\"): method_name = getattr(method, \"_rpc_method_name\", name) method_type = getattr(method, \"_rpc_method_type\", \"both\") if method_type in [\"request\", \"both\"]: self.register_request(method_name, method) if method_type in [\"response\", \"both\"]: self.register_response(method_name, method) self.logger.debug(f\"Registered request methods: {list(self.request_methods.keys())}\") self.logger.debug(f\"Registered response methods: {list(self.response_methods.keys())}\") register_request(method_name, method) Register a request handler. Parameters: method_name ( str ) \u2013 Name of the RPC method. method ( Callable ) \u2013 Function to call when this request is received. Raises: ValueError \u2013 If the provided method is not callable. Source code in python/neuro_rpc/RPCHandler.py def register_request(self, method_name: str, method: Callable) -> None: \"\"\" Register a request handler. Args: method_name (str): Name of the RPC method. method (Callable): Function to call when this request is received. Raises: ValueError: If the provided method is not callable. \"\"\" if not callable(method): raise ValueError(f\"Request handler for {method_name} must be callable\") if method_name in self.request_methods: self.logger.warning(f\"Overriding existing request method: {method_name}\") self.request_methods[method_name] = method register_response(method_name, method) Register a response handler. Parameters: method_name ( str ) \u2013 Name of the RPC method. method ( Callable ) \u2013 Function to call when a response is received. Raises: ValueError \u2013 If the provided method is not callable. Source code in python/neuro_rpc/RPCHandler.py def register_response(self, method_name: str, method: Callable) -> None: \"\"\" Register a response handler. Args: method_name (str): Name of the RPC method. method (Callable): Function to call when a response is received. Raises: ValueError: If the provided method is not callable. \"\"\" if not callable(method): raise ValueError(f\"Response handler for {method_name} must be callable\") if method_name in self.response_methods: self.logger.warning(f\"Overriding existing response method: {method_name}\") self.response_methods[method_name] = method rpc_method(method_type='both', name=None) Decorator to mark methods for RPC registration. Annotates a function so that RPCHandler.register_methods() can discover and register it as a request and/or response handler. Parameters: method_type ( str , default: 'both' ) \u2013 One of {\"request\", \"response\", \"both\"} (default \"both\"). name ( str , default: None ) \u2013 Optional alias under which the method is registered. Returns: Callable \u2013 The decorated function. Source code in python/neuro_rpc/RPCHandler.py def rpc_method(method_type: str = \"both\", name: Optional[str] = None): \"\"\" Decorator to mark methods for RPC registration. Annotates a function so that ``RPCHandler.register_methods()`` can discover and register it as a request and/or response handler. Args: method_type (str): One of {\"request\", \"response\", \"both\"} (default \"both\"). name (str, optional): Optional alias under which the method is registered. Returns: Callable: The decorated function. \"\"\" def decorator(func): func._is_rpc_method = True func._rpc_method_type = method_type func._rpc_method_name = name or func.__name__ return func if callable(method_type): func, method_type = method_type, \"both\" return decorator(func) return decorator","title":"RPCHandler"},{"location":"reference/RPCHandler/#rpchandler","text":"Registration and dispatch of RPC request/response methods. Implements a handler for JSON-Message 2.0 (similar to JSON-RPC 2.0), providing: - Method registration via the @rpc_method decorator. - Creation of request, response, and error messages. - Processing of incoming messages (both requests and responses). - Integration with Benchmark to track latency and round-trip times. Notes Acts as the bridge between raw JSON messages and Python method calls.","title":"RPCHandler"},{"location":"reference/RPCHandler/#neuro_rpc.RPCHandler.RPCHandler","text":"Bases: RPCMessage Core handler for JSON-Message 2.0 operations. Manages registration of request/response handlers, creation of message objects, and routing of incoming messages. Integrates with Benchmark to track requests and responses. Initialize the RPCHandler. Creates registries for request/response methods, sets up a Benchmark tracker, and initializes a logger. Source code in python/neuro_rpc/RPCHandler.py def __init__(self): \"\"\" Initialize the RPCHandler. Creates registries for request/response methods, sets up a Benchmark tracker, and initializes a logger. \"\"\" super().__init__() self.request_methods: Dict[str, Callable] = {} self.response_methods: Dict[str, Callable] = {} self._request_id = 0 self.tracker = Benchmark() self.logger = Logger.get_logger(self.__class__.__name__)","title":"RPCHandler"},{"location":"reference/RPCHandler/#neuro_rpc.RPCHandler.RPCHandler.create_error","text":"Create a JSON-Message error object. Parameters: error_type ( str | dict ) \u2013 Error type (see RPCError constants). data ( Any , default: None ) \u2013 Additional error details. id ( str , default: None ) \u2013 ID of the related request. Returns: dict \u2013 Serialized error response object. Source code in python/neuro_rpc/RPCHandler.py def create_error(self, error_type, data=None, id=None): \"\"\" Create a JSON-Message error object. Args: error_type (str | dict): Error type (see RPCError constants). data (Any, optional): Additional error details. id (str, optional): ID of the related request. Returns: dict: Serialized error response object. \"\"\" error = RPCError(error_type=error_type, data=data) response = RPCResponse(error=error.error, id=id) if self.tracker: self.tracker.track_outgoing_response(response) return response.to_dict()","title":"create_error"},{"location":"reference/RPCHandler/#neuro_rpc.RPCHandler.RPCHandler.create_request","text":"Create a JSON-Message request object. Parameters: method ( str ) \u2013 Method name to call. params ( dict | list , default: None ) \u2013 Parameters for the request. request_id ( str , default: None ) \u2013 Custom request ID (UUID by default). Returns: dict \u2013 Serialized request object. Source code in python/neuro_rpc/RPCHandler.py def create_request(self, method, params=None, request_id=None): \"\"\" Create a JSON-Message request object. Args: method (str): Method name to call. params (dict | list, optional): Parameters for the request. request_id (str, optional): Custom request ID (UUID by default). Returns: dict: Serialized request object. \"\"\" if request_id is None: request_id = str(uuid.uuid4()) request = RPCRequest(method=method, id=request_id, params=params) request_dict = request.to_dict() if self.tracker: self.tracker.track_outgoing_request(request) return request_dict","title":"create_request"},{"location":"reference/RPCHandler/#neuro_rpc.RPCHandler.RPCHandler.create_response","text":"Create a JSON-Message response object. Parameters: result ( Any ) \u2013 The result to return. request_id ( str ) \u2013 ID of the original request. Returns: dict \u2013 Serialized response object. Source code in python/neuro_rpc/RPCHandler.py def create_response(self, result, request_id): \"\"\" Create a JSON-Message response object. Args: result (Any): The result to return. request_id (str): ID of the original request. Returns: dict: Serialized response object. \"\"\" response = RPCResponse(result=result, id=request_id) response_dict = response.to_dict() if self.tracker: self.tracker.track_outgoing_response(response) return response_dict","title":"create_response"},{"location":"reference/RPCHandler/#neuro_rpc.RPCHandler.RPCHandler.next_request_id","text":"Generate a new request ID. Returns: int ( int ) \u2013 Incremental request ID. Source code in python/neuro_rpc/RPCHandler.py def next_request_id(self) -> int: \"\"\" Generate a new request ID. Returns: int: Incremental request ID. \"\"\" self._request_id += 1 return self._request_id","title":"next_request_id"},{"location":"reference/RPCHandler/#neuro_rpc.RPCHandler.RPCHandler.process_message","text":"Process an incoming JSON-Message. Parses input (string/dict/RPCMessage), converts to RPCRequest or RPCResponse, and dispatches to the appropriate handler. Parameters: message ( dict | str | RPCMessage ) \u2013 Incoming message. Returns: Optional [ Dict [ str , Any ]] \u2013 dict | None: Response dict if request, None if response. Raises: RPCError \u2013 If message is invalid or cannot be parsed. Source code in python/neuro_rpc/RPCHandler.py def process_message(self, message: Union[Dict[str, Any], str, RPCMessage]) -> Optional[Dict[str, Any]]: \"\"\" Process an incoming JSON-Message. Parses input (string/dict/RPCMessage), converts to RPCRequest or RPCResponse, and dispatches to the appropriate handler. Args: message (dict | str | RPCMessage): Incoming message. Returns: dict | None: Response dict if request, None if response. Raises: RPCError: If message is invalid or cannot be parsed. \"\"\" try: if isinstance(message, str): try: import json message = json.loads(message) except Exception as e: self.logger.error(f\"JSON parse error: {e}\") return self.create_error(RPCError.PARSE_ERROR) if isinstance(message, dict): if \"method\" in message: try: rpc_message = RPCRequest.from_dict(message) except Exception: return self.create_error(RPCError.INVALID_REQUEST) elif \"result\" in message or \"error\" in message: try: rpc_message = RPCResponse.from_dict(message) except Exception: return self.create_error(RPCError.INVALID_REQUEST) else: return self.create_error(RPCError.INVALID_REQUEST) else: return self.create_error(RPCError.INVALID_REQUEST) if isinstance(rpc_message, RPCRequest): return self._process_request(rpc_message) elif isinstance(rpc_message, RPCResponse): self._process_response(rpc_message) return None else: return self.create_error(RPCError.INVALID_REQUEST) except Exception as e: self.logger.error(f\"Error processing message: {e}\", exc_info=True) return self.create_error(RPCError.INTERNAL_ERROR, data=str(e))","title":"process_message"},{"location":"reference/RPCHandler/#neuro_rpc.RPCHandler.RPCHandler.register_methods","text":"Register decorated methods from an instance. Scans instance methods and registers those annotated with @rpc_method . Parameters: instance ( Any ) \u2013 Object instance containing decorated methods. Source code in python/neuro_rpc/RPCHandler.py def register_methods(self, instance) -> None: \"\"\" Register decorated methods from an instance. Scans instance methods and registers those annotated with ``@rpc_method``. Args: instance (Any): Object instance containing decorated methods. \"\"\" for name, method in inspect.getmembers(instance, predicate=inspect.ismethod): if hasattr(method, \"_is_rpc_method\"): method_name = getattr(method, \"_rpc_method_name\", name) method_type = getattr(method, \"_rpc_method_type\", \"both\") if method_type in [\"request\", \"both\"]: self.register_request(method_name, method) if method_type in [\"response\", \"both\"]: self.register_response(method_name, method) self.logger.debug(f\"Registered request methods: {list(self.request_methods.keys())}\") self.logger.debug(f\"Registered response methods: {list(self.response_methods.keys())}\")","title":"register_methods"},{"location":"reference/RPCHandler/#neuro_rpc.RPCHandler.RPCHandler.register_request","text":"Register a request handler. Parameters: method_name ( str ) \u2013 Name of the RPC method. method ( Callable ) \u2013 Function to call when this request is received. Raises: ValueError \u2013 If the provided method is not callable. Source code in python/neuro_rpc/RPCHandler.py def register_request(self, method_name: str, method: Callable) -> None: \"\"\" Register a request handler. Args: method_name (str): Name of the RPC method. method (Callable): Function to call when this request is received. Raises: ValueError: If the provided method is not callable. \"\"\" if not callable(method): raise ValueError(f\"Request handler for {method_name} must be callable\") if method_name in self.request_methods: self.logger.warning(f\"Overriding existing request method: {method_name}\") self.request_methods[method_name] = method","title":"register_request"},{"location":"reference/RPCHandler/#neuro_rpc.RPCHandler.RPCHandler.register_response","text":"Register a response handler. Parameters: method_name ( str ) \u2013 Name of the RPC method. method ( Callable ) \u2013 Function to call when a response is received. Raises: ValueError \u2013 If the provided method is not callable. Source code in python/neuro_rpc/RPCHandler.py def register_response(self, method_name: str, method: Callable) -> None: \"\"\" Register a response handler. Args: method_name (str): Name of the RPC method. method (Callable): Function to call when a response is received. Raises: ValueError: If the provided method is not callable. \"\"\" if not callable(method): raise ValueError(f\"Response handler for {method_name} must be callable\") if method_name in self.response_methods: self.logger.warning(f\"Overriding existing response method: {method_name}\") self.response_methods[method_name] = method","title":"register_response"},{"location":"reference/RPCHandler/#neuro_rpc.RPCHandler.rpc_method","text":"Decorator to mark methods for RPC registration. Annotates a function so that RPCHandler.register_methods() can discover and register it as a request and/or response handler. Parameters: method_type ( str , default: 'both' ) \u2013 One of {\"request\", \"response\", \"both\"} (default \"both\"). name ( str , default: None ) \u2013 Optional alias under which the method is registered. Returns: Callable \u2013 The decorated function. Source code in python/neuro_rpc/RPCHandler.py def rpc_method(method_type: str = \"both\", name: Optional[str] = None): \"\"\" Decorator to mark methods for RPC registration. Annotates a function so that ``RPCHandler.register_methods()`` can discover and register it as a request and/or response handler. Args: method_type (str): One of {\"request\", \"response\", \"both\"} (default \"both\"). name (str, optional): Optional alias under which the method is registered. Returns: Callable: The decorated function. \"\"\" def decorator(func): func._is_rpc_method = True func._rpc_method_type = method_type func._rpc_method_name = name or func.__name__ return func if callable(method_type): func, method_type = method_type, \"both\" return decorator(func) return decorator","title":"rpc_method"},{"location":"reference/RPCMessage/","text":"RPCMessage Message and error classes for JSON-Message 2.0 protocol. Provides base classes for JSON-Message 2.0 communication (similar to JSON-RPC 2.0): - RPCError: structured error objects. - RPCMessage: base class for all messages. - RPCRequest: request with method, params, and id. - RPCResponse: response with result or error. Notes Ensures compatibility with NeuroRPC stack (Client, RPCHandler, Benchmark). RPCError(error_type=None, data=None) Bases: Exception Exception class for JSON-Message 2.0 errors. Encapsulates standard and implementation-specific error codes as structured dictionaries, used for request/response validation. Initialize RPCError with a given type and optional metadata. Parameters: error_type ( str | dict , default: None ) \u2013 One of the error constants or a full error dict. data ( Any , default: None ) \u2013 Additional metadata attached as \"metadata\" field. Source code in python/neuro_rpc/RPCMessage.py def __init__(self, error_type=None, data: Any = None): \"\"\" Initialize RPCError with a given type and optional metadata. Args: error_type (str | dict): One of the error constants or a full error dict. data (Any, optional): Additional metadata attached as \"metadata\" field. \"\"\" if isinstance(error_type, dict): self.error_type = None self.error = error_type.copy() if data is not None: self.error[\"metadata\"] = data else: self.error_type = error_type self.error = self._create_error(error_type, data) super().__init__(f\"{self.error['code']}: {self.error['message']} - {data if data else ''}\") RPCMessage() Base class for JSON-Message 2.0 messages. Defines the jsonrpc version and common serialization/deserialization helpers. Initialize with version '2.0'. Source code in python/neuro_rpc/RPCMessage.py def __init__(self): \"\"\"Initialize with version '2.0'.\"\"\" self.jsonrpc = \"2.0\" from_dict(data) classmethod Validate and create a message from dictionary. Parameters: data ( dict ) \u2013 Dictionary to parse. Returns: RPCMessage ( RPCMessage ) \u2013 Instance of the base class. Raises: RPCError \u2013 If input is not a dict or version is invalid. Source code in python/neuro_rpc/RPCMessage.py @classmethod def from_dict(cls, data: Dict[str, Any]) -> 'RPCMessage': \"\"\" Validate and create a message from dictionary. Args: data (dict): Dictionary to parse. Returns: RPCMessage: Instance of the base class. Raises: RPCError: If input is not a dict or version is invalid. \"\"\" if not isinstance(data, dict): raise RPCError(RPCError.INVALID_REQUEST, \"Data must be a dictionary\") if data.get(\"jsonrpc\") != \"2.0\": raise RPCError(RPCError.INVALID_REQUEST, \"Invalid JSON-Message version\") return cls() from_json(json_str) classmethod Create message from JSON string. Parameters: json_str ( str ) \u2013 Input JSON string. Returns: RPCMessage ( RPCMessage ) \u2013 Parsed object. Raises: RPCError \u2013 If parsing fails. Source code in python/neuro_rpc/RPCMessage.py @classmethod def from_json(cls, json_str: str) -> 'RPCMessage': \"\"\" Create message from JSON string. Args: json_str (str): Input JSON string. Returns: RPCMessage: Parsed object. Raises: RPCError: If parsing fails. \"\"\" try: data = json.loads(json_str) return cls.from_dict(data) except json.JSONDecodeError: raise RPCError(RPCError.PARSE_ERROR, \"Invalid JSON string\") to_dict() Serialize the message to a dictionary. Returns: dict ( Dict [ str , Any ] ) \u2013 Dictionary containing the jsonrpc version. Source code in python/neuro_rpc/RPCMessage.py def to_dict(self) -> Dict[str, Any]: \"\"\" Serialize the message to a dictionary. Returns: dict: Dictionary containing the ``jsonrpc`` version. \"\"\" return {\"jsonrpc\": self.jsonrpc} to_json() Serialize the message to a JSON string. Returns: str ( str ) \u2013 JSON string with message content. Source code in python/neuro_rpc/RPCMessage.py def to_json(self) -> str: \"\"\" Serialize the message to a JSON string. Returns: str: JSON string with message content. \"\"\" return json.dumps(self.to_dict()) RPCRequest(method, id=None, params=None) Bases: RPCMessage JSON-Message 2.0 Request. Contains method name, parameters, and identifier (id). Supports both positional (list) and named (dict) parameters. Parameters: method ( str ) \u2013 Method name to call. id ( Any , default: None ) \u2013 Identifier for correlation (None for notifications). params ( dict | list , default: None ) \u2013 Parameters for the call. Source code in python/neuro_rpc/RPCMessage.py def __init__(self, method: str, id: Any = None, params: Optional[Union[Dict, List]] = None): \"\"\" Args: method (str): Method name to call. id (Any, optional): Identifier for correlation (None for notifications). params (dict | list, optional): Parameters for the call. \"\"\" super().__init__() self.method = method self.id = id self.params = params is_notification property Check if this request is a notification. Notifications do not have an id and therefore do not expect a response. Returns: bool ( bool ) \u2013 True if id is None. from_dict(data) classmethod Create a request from dictionary. Parameters: data ( dict ) \u2013 Input dictionary. Returns: RPCRequest ( RPCRequest ) \u2013 Parsed request. Raises: RPCError \u2013 If validation fails. Source code in python/neuro_rpc/RPCMessage.py @classmethod def from_dict(cls, data: Dict[str, Any]) -> 'RPCRequest': \"\"\" Create a request from dictionary. Args: data (dict): Input dictionary. Returns: RPCRequest: Parsed request. Raises: RPCError: If validation fails. \"\"\" RPCMessage.from_dict(data) if \"method\" not in data or not isinstance(data[\"method\"], str): raise RPCError(RPCError.INVALID_REQUEST, \"Request must include a valid method name\") method = data[\"method\"] id = data.get(\"id\") params = data.get(\"params\") return cls(method=method, id=id, params=params) to_dict() Serialize the request to a dictionary. Returns: dict ( Dict [ str , Any ] ) \u2013 Request with jsonrpc, method, id, and params. Source code in python/neuro_rpc/RPCMessage.py def to_dict(self) -> Dict[str, Any]: \"\"\" Serialize the request to a dictionary. Returns: dict: Request with jsonrpc, method, id, and params. \"\"\" request = super().to_dict() request[\"method\"] = self.method if self.id is not None: request[\"id\"] = self.id if self.params is not None: request[\"params\"] = self.params return request RPCResponse(id, result=None, error=None, exec_time=None) Bases: RPCMessage JSON-Message 2.0 Response. Contains either a result or an error , but never both. Optionally includes execution time (exec_time) for benchmarking. Parameters: id ( Any ) \u2013 ID of the original request. result ( Any , default: None ) \u2013 Result of the request. error ( dict , default: None ) \u2013 Error object. exec_time ( int , default: None ) \u2013 Execution time (\u03bcs, provided by server). Raises: RPCError \u2013 If both result and error are provided. Source code in python/neuro_rpc/RPCMessage.py def __init__( self, id: Any, result: Any = None, error: Optional[Dict[str, Any]] = None, exec_time: Optional[int] = None, ): \"\"\" Args: id (Any): ID of the original request. result (Any, optional): Result of the request. error (dict, optional): Error object. exec_time (int, optional): Execution time (\u03bcs, provided by server). Raises: RPCError: If both result and error are provided. \"\"\" super().__init__() self.id = id if error is not None and result is not None: raise RPCError(\"INVALID_REQUEST\", \"Response cannot contain both result and error\") self.result = result self.error = error self.exec_time = exec_time is_error property Check if this response is an error response. Returns: bool ( bool ) \u2013 True if error is not None. is_success property Check if this response is a success response. Returns: bool ( bool ) \u2013 True if error is None. from_dict(data) classmethod Create a response from dictionary. Parameters: data ( dict ) \u2013 Input dictionary. Returns: RPCResponse ( RPCResponse ) \u2013 Parsed response. Raises: RPCError \u2013 If validation fails. Source code in python/neuro_rpc/RPCMessage.py @classmethod def from_dict(cls, data: Dict[str, Any]) -> 'RPCResponse': \"\"\" Create a response from dictionary. Args: data (dict): Input dictionary. Returns: RPCResponse: Parsed response. Raises: RPCError: If validation fails. \"\"\" RPCMessage.from_dict(data) if \"id\" not in data: raise RPCError(RPCError.INVALID_REQUEST, \"Response must include an ID\") if \"result\" in data and \"error\" in data: raise RPCError(RPCError.INVALID_REQUEST, \"Response cannot contain both result and error\") if \"result\" not in data and \"error\" not in data: raise RPCError(RPCError.INVALID_REQUEST, \"Response must contain either result or error\") id = data[\"id\"] result = data.get(\"result\") error = data.get(\"error\") exec_time = data.get(\"exec_time\", 0) return cls(id=id, result=result, error=error, exec_time=exec_time) to_dict() Serialize the response to a dictionary. Returns: dict ( Dict [ str , Any ] ) \u2013 Response with jsonrpc, id, and either result or error. Source code in python/neuro_rpc/RPCMessage.py def to_dict(self) -> Dict[str, Any]: \"\"\" Serialize the response to a dictionary. Returns: dict: Response with jsonrpc, id, and either result or error. \"\"\" response = super().to_dict() response[\"id\"] = self.id if self.error is not None: response[\"error\"] = self.error else: response[\"result\"] = self.result if self.exec_time is not None: response[\"exec_time\"] = self.exec_time return response","title":"RPCMessage"},{"location":"reference/RPCMessage/#rpcmessage","text":"Message and error classes for JSON-Message 2.0 protocol. Provides base classes for JSON-Message 2.0 communication (similar to JSON-RPC 2.0): - RPCError: structured error objects. - RPCMessage: base class for all messages. - RPCRequest: request with method, params, and id. - RPCResponse: response with result or error. Notes Ensures compatibility with NeuroRPC stack (Client, RPCHandler, Benchmark).","title":"RPCMessage"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCError","text":"Bases: Exception Exception class for JSON-Message 2.0 errors. Encapsulates standard and implementation-specific error codes as structured dictionaries, used for request/response validation. Initialize RPCError with a given type and optional metadata. Parameters: error_type ( str | dict , default: None ) \u2013 One of the error constants or a full error dict. data ( Any , default: None ) \u2013 Additional metadata attached as \"metadata\" field. Source code in python/neuro_rpc/RPCMessage.py def __init__(self, error_type=None, data: Any = None): \"\"\" Initialize RPCError with a given type and optional metadata. Args: error_type (str | dict): One of the error constants or a full error dict. data (Any, optional): Additional metadata attached as \"metadata\" field. \"\"\" if isinstance(error_type, dict): self.error_type = None self.error = error_type.copy() if data is not None: self.error[\"metadata\"] = data else: self.error_type = error_type self.error = self._create_error(error_type, data) super().__init__(f\"{self.error['code']}: {self.error['message']} - {data if data else ''}\")","title":"RPCError"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCMessage","text":"Base class for JSON-Message 2.0 messages. Defines the jsonrpc version and common serialization/deserialization helpers. Initialize with version '2.0'. Source code in python/neuro_rpc/RPCMessage.py def __init__(self): \"\"\"Initialize with version '2.0'.\"\"\" self.jsonrpc = \"2.0\"","title":"RPCMessage"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCMessage.from_dict","text":"Validate and create a message from dictionary. Parameters: data ( dict ) \u2013 Dictionary to parse. Returns: RPCMessage ( RPCMessage ) \u2013 Instance of the base class. Raises: RPCError \u2013 If input is not a dict or version is invalid. Source code in python/neuro_rpc/RPCMessage.py @classmethod def from_dict(cls, data: Dict[str, Any]) -> 'RPCMessage': \"\"\" Validate and create a message from dictionary. Args: data (dict): Dictionary to parse. Returns: RPCMessage: Instance of the base class. Raises: RPCError: If input is not a dict or version is invalid. \"\"\" if not isinstance(data, dict): raise RPCError(RPCError.INVALID_REQUEST, \"Data must be a dictionary\") if data.get(\"jsonrpc\") != \"2.0\": raise RPCError(RPCError.INVALID_REQUEST, \"Invalid JSON-Message version\") return cls()","title":"from_dict"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCMessage.from_json","text":"Create message from JSON string. Parameters: json_str ( str ) \u2013 Input JSON string. Returns: RPCMessage ( RPCMessage ) \u2013 Parsed object. Raises: RPCError \u2013 If parsing fails. Source code in python/neuro_rpc/RPCMessage.py @classmethod def from_json(cls, json_str: str) -> 'RPCMessage': \"\"\" Create message from JSON string. Args: json_str (str): Input JSON string. Returns: RPCMessage: Parsed object. Raises: RPCError: If parsing fails. \"\"\" try: data = json.loads(json_str) return cls.from_dict(data) except json.JSONDecodeError: raise RPCError(RPCError.PARSE_ERROR, \"Invalid JSON string\")","title":"from_json"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCMessage.to_dict","text":"Serialize the message to a dictionary. Returns: dict ( Dict [ str , Any ] ) \u2013 Dictionary containing the jsonrpc version. Source code in python/neuro_rpc/RPCMessage.py def to_dict(self) -> Dict[str, Any]: \"\"\" Serialize the message to a dictionary. Returns: dict: Dictionary containing the ``jsonrpc`` version. \"\"\" return {\"jsonrpc\": self.jsonrpc}","title":"to_dict"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCMessage.to_json","text":"Serialize the message to a JSON string. Returns: str ( str ) \u2013 JSON string with message content. Source code in python/neuro_rpc/RPCMessage.py def to_json(self) -> str: \"\"\" Serialize the message to a JSON string. Returns: str: JSON string with message content. \"\"\" return json.dumps(self.to_dict())","title":"to_json"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCRequest","text":"Bases: RPCMessage JSON-Message 2.0 Request. Contains method name, parameters, and identifier (id). Supports both positional (list) and named (dict) parameters. Parameters: method ( str ) \u2013 Method name to call. id ( Any , default: None ) \u2013 Identifier for correlation (None for notifications). params ( dict | list , default: None ) \u2013 Parameters for the call. Source code in python/neuro_rpc/RPCMessage.py def __init__(self, method: str, id: Any = None, params: Optional[Union[Dict, List]] = None): \"\"\" Args: method (str): Method name to call. id (Any, optional): Identifier for correlation (None for notifications). params (dict | list, optional): Parameters for the call. \"\"\" super().__init__() self.method = method self.id = id self.params = params","title":"RPCRequest"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCRequest.is_notification","text":"Check if this request is a notification. Notifications do not have an id and therefore do not expect a response. Returns: bool ( bool ) \u2013 True if id is None.","title":"is_notification"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCRequest.from_dict","text":"Create a request from dictionary. Parameters: data ( dict ) \u2013 Input dictionary. Returns: RPCRequest ( RPCRequest ) \u2013 Parsed request. Raises: RPCError \u2013 If validation fails. Source code in python/neuro_rpc/RPCMessage.py @classmethod def from_dict(cls, data: Dict[str, Any]) -> 'RPCRequest': \"\"\" Create a request from dictionary. Args: data (dict): Input dictionary. Returns: RPCRequest: Parsed request. Raises: RPCError: If validation fails. \"\"\" RPCMessage.from_dict(data) if \"method\" not in data or not isinstance(data[\"method\"], str): raise RPCError(RPCError.INVALID_REQUEST, \"Request must include a valid method name\") method = data[\"method\"] id = data.get(\"id\") params = data.get(\"params\") return cls(method=method, id=id, params=params)","title":"from_dict"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCRequest.to_dict","text":"Serialize the request to a dictionary. Returns: dict ( Dict [ str , Any ] ) \u2013 Request with jsonrpc, method, id, and params. Source code in python/neuro_rpc/RPCMessage.py def to_dict(self) -> Dict[str, Any]: \"\"\" Serialize the request to a dictionary. Returns: dict: Request with jsonrpc, method, id, and params. \"\"\" request = super().to_dict() request[\"method\"] = self.method if self.id is not None: request[\"id\"] = self.id if self.params is not None: request[\"params\"] = self.params return request","title":"to_dict"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCResponse","text":"Bases: RPCMessage JSON-Message 2.0 Response. Contains either a result or an error , but never both. Optionally includes execution time (exec_time) for benchmarking. Parameters: id ( Any ) \u2013 ID of the original request. result ( Any , default: None ) \u2013 Result of the request. error ( dict , default: None ) \u2013 Error object. exec_time ( int , default: None ) \u2013 Execution time (\u03bcs, provided by server). Raises: RPCError \u2013 If both result and error are provided. Source code in python/neuro_rpc/RPCMessage.py def __init__( self, id: Any, result: Any = None, error: Optional[Dict[str, Any]] = None, exec_time: Optional[int] = None, ): \"\"\" Args: id (Any): ID of the original request. result (Any, optional): Result of the request. error (dict, optional): Error object. exec_time (int, optional): Execution time (\u03bcs, provided by server). Raises: RPCError: If both result and error are provided. \"\"\" super().__init__() self.id = id if error is not None and result is not None: raise RPCError(\"INVALID_REQUEST\", \"Response cannot contain both result and error\") self.result = result self.error = error self.exec_time = exec_time","title":"RPCResponse"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCResponse.is_error","text":"Check if this response is an error response. Returns: bool ( bool ) \u2013 True if error is not None.","title":"is_error"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCResponse.is_success","text":"Check if this response is a success response. Returns: bool ( bool ) \u2013 True if error is None.","title":"is_success"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCResponse.from_dict","text":"Create a response from dictionary. Parameters: data ( dict ) \u2013 Input dictionary. Returns: RPCResponse ( RPCResponse ) \u2013 Parsed response. Raises: RPCError \u2013 If validation fails. Source code in python/neuro_rpc/RPCMessage.py @classmethod def from_dict(cls, data: Dict[str, Any]) -> 'RPCResponse': \"\"\" Create a response from dictionary. Args: data (dict): Input dictionary. Returns: RPCResponse: Parsed response. Raises: RPCError: If validation fails. \"\"\" RPCMessage.from_dict(data) if \"id\" not in data: raise RPCError(RPCError.INVALID_REQUEST, \"Response must include an ID\") if \"result\" in data and \"error\" in data: raise RPCError(RPCError.INVALID_REQUEST, \"Response cannot contain both result and error\") if \"result\" not in data and \"error\" not in data: raise RPCError(RPCError.INVALID_REQUEST, \"Response must contain either result or error\") id = data[\"id\"] result = data.get(\"result\") error = data.get(\"error\") exec_time = data.get(\"exec_time\", 0) return cls(id=id, result=result, error=error, exec_time=exec_time)","title":"from_dict"},{"location":"reference/RPCMessage/#neuro_rpc.RPCMessage.RPCResponse.to_dict","text":"Serialize the response to a dictionary. Returns: dict ( Dict [ str , Any ] ) \u2013 Response with jsonrpc, id, and either result or error. Source code in python/neuro_rpc/RPCMessage.py def to_dict(self) -> Dict[str, Any]: \"\"\" Serialize the response to a dictionary. Returns: dict: Response with jsonrpc, id, and either result or error. \"\"\" response = super().to_dict() response[\"id\"] = self.id if self.error is not None: response[\"error\"] = self.error else: response[\"result\"] = self.result if self.exec_time is not None: response[\"exec_time\"] = self.exec_time return response","title":"to_dict"},{"location":"reference/RPCMethods/","text":"RPCMethods Example RPC methods built on top of RPCHandler. Provides a container of request/response methods for testing and demonstration. Includes echo, add, subtract, and a default response handler. Can be extended with custom RPC logic as needed. Notes Uses the @rpc_method decorator to auto-register methods with RPCHandler. RPCMethods(auto_register=True) Bases: RPCHandler Container for RPC methods. Extends RPCHandler and defines example request/response methods that are automatically registered at initialization if auto_register=True . Initialize the RPCMethods container. Parameters: auto_register ( bool , default: True ) \u2013 If True, automatically registers decorated methods. Source code in python/neuro_rpc/RPCMethods.py def __init__(self, auto_register: bool = True): \"\"\" Initialize the RPCMethods container. Args: auto_register (bool): If True, automatically registers decorated methods. \"\"\" super().__init__() if auto_register: self.register_methods(self) add(a, b) RPC request method: add two numbers. Parameters: a ( float ) \u2013 First number. b ( float ) \u2013 Second number. Returns: float ( float ) \u2013 Sum of a and b. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"request\") def add(self, a: float, b: float) -> float: \"\"\" RPC request method: add two numbers. Args: a (float): First number. b (float): Second number. Returns: float: Sum of a and b. \"\"\" return a + b default_response_handler(id=None, result=None, error=None) Default response handler. Invoked if no specific handler is registered for a response. Parameters: id ( Any , default: None ) \u2013 ID of the response. result ( Any , default: None ) \u2013 Result payload if success. error ( Any , default: None ) \u2013 Error payload if failure. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"response\", name=\"default\") def default_response_handler(self, id: Any = None, result: Any = None, error: Any = None) -> None: \"\"\" Default response handler. Invoked if no specific handler is registered for a response. Args: id (Any, optional): ID of the response. result (Any, optional): Result payload if success. error (Any, optional): Error payload if failure. \"\"\" if error: logger.warning(f\"Unhandled response error for ID {id}: {error}\") else: logger.debug(f\"Unhandled response result for ID {id}: {result}\") echo(message) RPC request method: echo a message. Parameters: message ( str ) \u2013 String to echo back. Returns: str ( str ) \u2013 The same message received. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"request\") def echo(self, message: str) -> str: \"\"\" RPC request method: echo a message. Args: message (str): String to echo back. Returns: str: The same message received. \"\"\" return message handle_add_response(id=None, result=None, error=None) Response handler for add. Parameters: id ( Any , default: None ) \u2013 ID of the corresponding request. result ( Any , default: None ) \u2013 Result (sum). error ( Any , default: None ) \u2013 Error object if the request failed. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"response\", name=\"add\") def handle_add_response(self, id: Any = None, result: Any = None, error: Any = None) -> None: \"\"\" Response handler for add. Args: id (Any, optional): ID of the corresponding request. result (Any, optional): Result (sum). error (Any, optional): Error object if the request failed. \"\"\" if error: logger.error(f\"Add operation failed: {error}\") else: logger.debug(f\"Add operation result: {result}\") handle_echo_response(id=None, result=None, error=None) Response handler for echo. Parameters: id ( Any , default: None ) \u2013 ID of the corresponding request. result ( Any , default: None ) \u2013 Result content. error ( Any , default: None ) \u2013 Error object if the request failed. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"response\", name=\"echo\") def handle_echo_response(self, id: Any = None, result: Any = None, error: Any = None) -> None: \"\"\" Response handler for echo. Args: id (Any, optional): ID of the corresponding request. result (Any, optional): Result content. error (Any, optional): Error object if the request failed. \"\"\" if error: logger.error(f\"Echo operation failed: {error}\") else: pass handle_subtract_response(id=None, result=None, error=None) Response handler for subtract. Parameters: id ( Any , default: None ) \u2013 ID of the corresponding request. result ( Any , default: None ) \u2013 Result (difference). error ( Any , default: None ) \u2013 Error object if the request failed. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"response\", name=\"subtract\") def handle_subtract_response(self, id: Any = None, result: Any = None, error: Any = None) -> None: \"\"\" Response handler for subtract. Args: id (Any, optional): ID of the corresponding request. result (Any, optional): Result (difference). error (Any, optional): Error object if the request failed. \"\"\" if error: logger.error(f\"Subtract operation failed: {error}\") else: logger.debug(f\"Subtract operation result: {result}\") subtract(a, b) RPC request method: subtract b from a. Parameters: a ( float ) \u2013 Minuend. b ( float ) \u2013 Subtrahend. Returns: float ( float ) \u2013 Result of a - b. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"request\") def subtract(self, a: float, b: float) -> float: \"\"\" RPC request method: subtract b from a. Args: a (float): Minuend. b (float): Subtrahend. Returns: float: Result of a - b. \"\"\" return a - b","title":"RPCMethods"},{"location":"reference/RPCMethods/#rpcmethods","text":"Example RPC methods built on top of RPCHandler. Provides a container of request/response methods for testing and demonstration. Includes echo, add, subtract, and a default response handler. Can be extended with custom RPC logic as needed. Notes Uses the @rpc_method decorator to auto-register methods with RPCHandler.","title":"RPCMethods"},{"location":"reference/RPCMethods/#neuro_rpc.RPCMethods.RPCMethods","text":"Bases: RPCHandler Container for RPC methods. Extends RPCHandler and defines example request/response methods that are automatically registered at initialization if auto_register=True . Initialize the RPCMethods container. Parameters: auto_register ( bool , default: True ) \u2013 If True, automatically registers decorated methods. Source code in python/neuro_rpc/RPCMethods.py def __init__(self, auto_register: bool = True): \"\"\" Initialize the RPCMethods container. Args: auto_register (bool): If True, automatically registers decorated methods. \"\"\" super().__init__() if auto_register: self.register_methods(self)","title":"RPCMethods"},{"location":"reference/RPCMethods/#neuro_rpc.RPCMethods.RPCMethods.add","text":"RPC request method: add two numbers. Parameters: a ( float ) \u2013 First number. b ( float ) \u2013 Second number. Returns: float ( float ) \u2013 Sum of a and b. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"request\") def add(self, a: float, b: float) -> float: \"\"\" RPC request method: add two numbers. Args: a (float): First number. b (float): Second number. Returns: float: Sum of a and b. \"\"\" return a + b","title":"add"},{"location":"reference/RPCMethods/#neuro_rpc.RPCMethods.RPCMethods.default_response_handler","text":"Default response handler. Invoked if no specific handler is registered for a response. Parameters: id ( Any , default: None ) \u2013 ID of the response. result ( Any , default: None ) \u2013 Result payload if success. error ( Any , default: None ) \u2013 Error payload if failure. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"response\", name=\"default\") def default_response_handler(self, id: Any = None, result: Any = None, error: Any = None) -> None: \"\"\" Default response handler. Invoked if no specific handler is registered for a response. Args: id (Any, optional): ID of the response. result (Any, optional): Result payload if success. error (Any, optional): Error payload if failure. \"\"\" if error: logger.warning(f\"Unhandled response error for ID {id}: {error}\") else: logger.debug(f\"Unhandled response result for ID {id}: {result}\")","title":"default_response_handler"},{"location":"reference/RPCMethods/#neuro_rpc.RPCMethods.RPCMethods.echo","text":"RPC request method: echo a message. Parameters: message ( str ) \u2013 String to echo back. Returns: str ( str ) \u2013 The same message received. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"request\") def echo(self, message: str) -> str: \"\"\" RPC request method: echo a message. Args: message (str): String to echo back. Returns: str: The same message received. \"\"\" return message","title":"echo"},{"location":"reference/RPCMethods/#neuro_rpc.RPCMethods.RPCMethods.handle_add_response","text":"Response handler for add. Parameters: id ( Any , default: None ) \u2013 ID of the corresponding request. result ( Any , default: None ) \u2013 Result (sum). error ( Any , default: None ) \u2013 Error object if the request failed. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"response\", name=\"add\") def handle_add_response(self, id: Any = None, result: Any = None, error: Any = None) -> None: \"\"\" Response handler for add. Args: id (Any, optional): ID of the corresponding request. result (Any, optional): Result (sum). error (Any, optional): Error object if the request failed. \"\"\" if error: logger.error(f\"Add operation failed: {error}\") else: logger.debug(f\"Add operation result: {result}\")","title":"handle_add_response"},{"location":"reference/RPCMethods/#neuro_rpc.RPCMethods.RPCMethods.handle_echo_response","text":"Response handler for echo. Parameters: id ( Any , default: None ) \u2013 ID of the corresponding request. result ( Any , default: None ) \u2013 Result content. error ( Any , default: None ) \u2013 Error object if the request failed. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"response\", name=\"echo\") def handle_echo_response(self, id: Any = None, result: Any = None, error: Any = None) -> None: \"\"\" Response handler for echo. Args: id (Any, optional): ID of the corresponding request. result (Any, optional): Result content. error (Any, optional): Error object if the request failed. \"\"\" if error: logger.error(f\"Echo operation failed: {error}\") else: pass","title":"handle_echo_response"},{"location":"reference/RPCMethods/#neuro_rpc.RPCMethods.RPCMethods.handle_subtract_response","text":"Response handler for subtract. Parameters: id ( Any , default: None ) \u2013 ID of the corresponding request. result ( Any , default: None ) \u2013 Result (difference). error ( Any , default: None ) \u2013 Error object if the request failed. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"response\", name=\"subtract\") def handle_subtract_response(self, id: Any = None, result: Any = None, error: Any = None) -> None: \"\"\" Response handler for subtract. Args: id (Any, optional): ID of the corresponding request. result (Any, optional): Result (difference). error (Any, optional): Error object if the request failed. \"\"\" if error: logger.error(f\"Subtract operation failed: {error}\") else: logger.debug(f\"Subtract operation result: {result}\")","title":"handle_subtract_response"},{"location":"reference/RPCMethods/#neuro_rpc.RPCMethods.RPCMethods.subtract","text":"RPC request method: subtract b from a. Parameters: a ( float ) \u2013 Minuend. b ( float ) \u2013 Subtrahend. Returns: float ( float ) \u2013 Result of a - b. Source code in python/neuro_rpc/RPCMethods.py @rpc_method(method_type=\"request\") def subtract(self, a: float, b: float) -> float: \"\"\" RPC request method: subtract b from a. Args: a (float): Minuend. b (float): Subtrahend. Returns: float: Result of a - b. \"\"\" return a - b","title":"subtract"},{"location":"reference/RPCTracker/","text":"RPCTracker Message tracking utility for JSON-Message 2.0 protocol. Tracks outgoing/incoming requests and responses, monitors for timeouts, keeps statistics, and runs an optional background monitoring thread. Designed for integration with RPCHandler and Benchmark to provide runtime visibility of pending and completed RPC calls. Notes Thread-safe using locks. Intended for long-running client/server sessions. RPCTracker(monitor_interval=1, cleanup_interval=60, autostart=True) Tracks request/response lifecycle for RPC messages. Maintains dictionaries of outgoing/incoming requests and responses, updates statistics, and detects timeouts via a background thread. Initialize RPCTracker. Parameters: monitor_interval ( int , default: 1 ) \u2013 Interval in seconds to check for timeouts. cleanup_interval ( int , default: 60 ) \u2013 Interval in seconds to clean old entries. autostart ( bool , default: True ) \u2013 Whether to immediately start monitoring. Source code in python/neuro_rpc/RPCTracker.py def __init__(self, monitor_interval=1, cleanup_interval=60, autostart=True): \"\"\" Initialize RPCTracker. Args: monitor_interval (int): Interval in seconds to check for timeouts. cleanup_interval (int): Interval in seconds to clean old entries. autostart (bool): Whether to immediately start monitoring. \"\"\" self.logger = Logger.get_logger(self.__class__.__name__) self.monitor_interval = monitor_interval self.cleanup_interval = cleanup_interval self._tracking_lock = threading.Lock() self.outgoing_requests = {} # {id: (timestamp, method_name, timeout)} self.incoming_requests = {} # {id: (timestamp, method_name)} self.outgoing_responses = {} # {id: (timestamp, success)} self.incoming_responses = {} # {id: (timestamp, success)} self.stats = { \"outgoing_requests_count\": 0, \"incoming_requests_count\": 0, \"outgoing_responses_count\": 0, \"incoming_responses_count\": 0, \"timed_out_requests\": 0 } self._monitor_thread = None self._should_stop = threading.Event() self.timeout_callback = None if autostart: self.start_monitoring() clean_tracking_data(max_age_seconds=3600) Remove old tracking entries. Parameters: max_age_seconds ( int , default: 3600 ) \u2013 Max age in seconds to keep entries. Returns: int \u2013 Number of entries cleaned. Source code in python/neuro_rpc/RPCTracker.py def clean_tracking_data(self, max_age_seconds=3600): \"\"\" Remove old tracking entries. Args: max_age_seconds (int): Max age in seconds to keep entries. Returns: int: Number of entries cleaned. \"\"\" now = time.time() cleaned = 0 with self._tracking_lock: for storage in [self.outgoing_requests, self.incoming_requests, self.outgoing_responses, self.incoming_responses]: for req_id, (timestamp, *_) in list(storage.items()): if now - timestamp > max_age_seconds: del storage[req_id] cleaned += 1 return cleaned get_statistics() Get current statistics snapshot. Returns: dict \u2013 Copy of statistics counters. Source code in python/neuro_rpc/RPCTracker.py def get_statistics(self): \"\"\" Get current statistics snapshot. Returns: dict: Copy of statistics counters. \"\"\" with self._tracking_lock: return self.stats.copy() monitor_messages() Inspect current requests for timeouts and pending states. Returns: dict \u2013 Dictionary with lists of timed-out and pending requests. Source code in python/neuro_rpc/RPCTracker.py def monitor_messages(self): \"\"\" Inspect current requests for timeouts and pending states. Returns: dict: Dictionary with lists of timed-out and pending requests. \"\"\" now = time.time() results = { \"timed_out_requests\": [], \"pending_outgoing_requests\": [], \"pending_incoming_requests\": [] } with self._tracking_lock: for req_id, (timestamp, method, timeout) in list(self.outgoing_requests.items()): elapsed = now - timestamp if elapsed > timeout: results[\"timed_out_requests\"].append((req_id, method, elapsed)) del self.outgoing_requests[req_id] self.stats[\"timed_out_requests\"] += 1 else: results[\"pending_outgoing_requests\"].append((req_id, method, elapsed)) for req_id, (timestamp, method) in list(self.incoming_requests.items()): elapsed = now - timestamp results[\"pending_incoming_requests\"].append((req_id, method, elapsed)) if self.logger: for req_id, method, elapsed in results[\"timed_out_requests\"]: self.logger.warning(f\"Request timed out: ID {req_id}, method {method}, elapsed {elapsed:.2f}s\") return results start_monitoring(timeout_callback=None) Start the background monitoring thread. Parameters: timeout_callback ( Callable , default: None ) \u2013 Callback called with a list of timed-out requests. Returns: bool \u2013 True if started, False if already running. Source code in python/neuro_rpc/RPCTracker.py def start_monitoring(self, timeout_callback=None): \"\"\" Start the background monitoring thread. Args: timeout_callback (Callable, optional): Callback called with a list of timed-out requests. Returns: bool: True if started, False if already running. \"\"\" if self._monitor_thread is not None and self._monitor_thread.is_alive(): if self.logger: self.logger.warning(\"Monitoring thread already running\") return False self.timeout_callback = timeout_callback self._should_stop.clear() self._monitor_thread = threading.Thread( target=self._monitor_loop, name=\"RPCTracker-Monitor\", daemon=True ) self._monitor_thread.start() if self.logger: self.logger.debug(\"Message tracking monitor started\") return True stop_monitoring() Stop the background monitoring thread. Returns: bool \u2013 True if stopped cleanly, False otherwise. Source code in python/neuro_rpc/RPCTracker.py def stop_monitoring(self): \"\"\" Stop the background monitoring thread. Returns: bool: True if stopped cleanly, False otherwise. \"\"\" if self._monitor_thread is None or not self._monitor_thread.is_alive(): return False self._should_stop.set() self._monitor_thread.join(timeout=5.0) if self._monitor_thread.is_alive(): if self.logger: self.logger.warning(\"Monitoring thread did not shut down cleanly\") return False else: if self.logger: self.logger.debug(\"Message tracking monitor stopped\") return True track_incoming_request(request) Track an incoming request from server. Parameters: request ( RPCRequest ) \u2013 Request object received. Source code in python/neuro_rpc/RPCTracker.py def track_incoming_request(self, request: RPCRequest): \"\"\" Track an incoming request from server. Args: request (RPCRequest): Request object received. \"\"\" with self._tracking_lock: self.logger.debug(f\"Tracking incoming request: {request}\") self.incoming_requests[request.id] = (time.time(), request.method) self.stats[\"incoming_requests_count\"] += 1 track_incoming_response(response) Track an incoming response from server. Parameters: response ( RPCResponse ) \u2013 Response object received. Source code in python/neuro_rpc/RPCTracker.py def track_incoming_response(self, response: RPCResponse): \"\"\" Track an incoming response from server. Args: response (RPCResponse): Response object received. \"\"\" with self._tracking_lock: if response.id in self.outgoing_requests: del self.outgoing_requests[response.id] self.stats[\"incoming_responses_count\"] += 1 else: if self.logger: self.logger.warning(f\"Received response for unknown request ID: {response.id}\") track_outgoing_request(request, timeout=60) Track an outgoing request. Parameters: request ( RPCRequest ) \u2013 Request object being sent. timeout ( int , default: 60 ) \u2013 Timeout in seconds for this request. Source code in python/neuro_rpc/RPCTracker.py def track_outgoing_request(self, request: RPCRequest, timeout=60): \"\"\" Track an outgoing request. Args: request (RPCRequest): Request object being sent. timeout (int): Timeout in seconds for this request. \"\"\" with self._tracking_lock: self.outgoing_requests[request.id] = (time.time(), request.method, timeout) self.stats[\"outgoing_requests_count\"] += 1 track_outgoing_response(response) Track an outgoing response. Parameters: response ( RPCResponse ) \u2013 Response object being sent. Source code in python/neuro_rpc/RPCTracker.py def track_outgoing_response(self, response: RPCResponse): \"\"\" Track an outgoing response. Args: response (RPCResponse): Response object being sent. \"\"\" with self._tracking_lock: self.logger.debug(f\"Tracking outgoing response: {response.id}, {response.is_success}\") if response.id in self.incoming_requests: del self.incoming_requests[response.id] self.outgoing_responses[response.id] = (time.time(), response.is_success) self.stats[\"outgoing_responses_count\"] += 1","title":"RPCTracker"},{"location":"reference/RPCTracker/#rpctracker","text":"Message tracking utility for JSON-Message 2.0 protocol. Tracks outgoing/incoming requests and responses, monitors for timeouts, keeps statistics, and runs an optional background monitoring thread. Designed for integration with RPCHandler and Benchmark to provide runtime visibility of pending and completed RPC calls. Notes Thread-safe using locks. Intended for long-running client/server sessions.","title":"RPCTracker"},{"location":"reference/RPCTracker/#neuro_rpc.RPCTracker.RPCTracker","text":"Tracks request/response lifecycle for RPC messages. Maintains dictionaries of outgoing/incoming requests and responses, updates statistics, and detects timeouts via a background thread. Initialize RPCTracker. Parameters: monitor_interval ( int , default: 1 ) \u2013 Interval in seconds to check for timeouts. cleanup_interval ( int , default: 60 ) \u2013 Interval in seconds to clean old entries. autostart ( bool , default: True ) \u2013 Whether to immediately start monitoring. Source code in python/neuro_rpc/RPCTracker.py def __init__(self, monitor_interval=1, cleanup_interval=60, autostart=True): \"\"\" Initialize RPCTracker. Args: monitor_interval (int): Interval in seconds to check for timeouts. cleanup_interval (int): Interval in seconds to clean old entries. autostart (bool): Whether to immediately start monitoring. \"\"\" self.logger = Logger.get_logger(self.__class__.__name__) self.monitor_interval = monitor_interval self.cleanup_interval = cleanup_interval self._tracking_lock = threading.Lock() self.outgoing_requests = {} # {id: (timestamp, method_name, timeout)} self.incoming_requests = {} # {id: (timestamp, method_name)} self.outgoing_responses = {} # {id: (timestamp, success)} self.incoming_responses = {} # {id: (timestamp, success)} self.stats = { \"outgoing_requests_count\": 0, \"incoming_requests_count\": 0, \"outgoing_responses_count\": 0, \"incoming_responses_count\": 0, \"timed_out_requests\": 0 } self._monitor_thread = None self._should_stop = threading.Event() self.timeout_callback = None if autostart: self.start_monitoring()","title":"RPCTracker"},{"location":"reference/RPCTracker/#neuro_rpc.RPCTracker.RPCTracker.clean_tracking_data","text":"Remove old tracking entries. Parameters: max_age_seconds ( int , default: 3600 ) \u2013 Max age in seconds to keep entries. Returns: int \u2013 Number of entries cleaned. Source code in python/neuro_rpc/RPCTracker.py def clean_tracking_data(self, max_age_seconds=3600): \"\"\" Remove old tracking entries. Args: max_age_seconds (int): Max age in seconds to keep entries. Returns: int: Number of entries cleaned. \"\"\" now = time.time() cleaned = 0 with self._tracking_lock: for storage in [self.outgoing_requests, self.incoming_requests, self.outgoing_responses, self.incoming_responses]: for req_id, (timestamp, *_) in list(storage.items()): if now - timestamp > max_age_seconds: del storage[req_id] cleaned += 1 return cleaned","title":"clean_tracking_data"},{"location":"reference/RPCTracker/#neuro_rpc.RPCTracker.RPCTracker.get_statistics","text":"Get current statistics snapshot. Returns: dict \u2013 Copy of statistics counters. Source code in python/neuro_rpc/RPCTracker.py def get_statistics(self): \"\"\" Get current statistics snapshot. Returns: dict: Copy of statistics counters. \"\"\" with self._tracking_lock: return self.stats.copy()","title":"get_statistics"},{"location":"reference/RPCTracker/#neuro_rpc.RPCTracker.RPCTracker.monitor_messages","text":"Inspect current requests for timeouts and pending states. Returns: dict \u2013 Dictionary with lists of timed-out and pending requests. Source code in python/neuro_rpc/RPCTracker.py def monitor_messages(self): \"\"\" Inspect current requests for timeouts and pending states. Returns: dict: Dictionary with lists of timed-out and pending requests. \"\"\" now = time.time() results = { \"timed_out_requests\": [], \"pending_outgoing_requests\": [], \"pending_incoming_requests\": [] } with self._tracking_lock: for req_id, (timestamp, method, timeout) in list(self.outgoing_requests.items()): elapsed = now - timestamp if elapsed > timeout: results[\"timed_out_requests\"].append((req_id, method, elapsed)) del self.outgoing_requests[req_id] self.stats[\"timed_out_requests\"] += 1 else: results[\"pending_outgoing_requests\"].append((req_id, method, elapsed)) for req_id, (timestamp, method) in list(self.incoming_requests.items()): elapsed = now - timestamp results[\"pending_incoming_requests\"].append((req_id, method, elapsed)) if self.logger: for req_id, method, elapsed in results[\"timed_out_requests\"]: self.logger.warning(f\"Request timed out: ID {req_id}, method {method}, elapsed {elapsed:.2f}s\") return results","title":"monitor_messages"},{"location":"reference/RPCTracker/#neuro_rpc.RPCTracker.RPCTracker.start_monitoring","text":"Start the background monitoring thread. Parameters: timeout_callback ( Callable , default: None ) \u2013 Callback called with a list of timed-out requests. Returns: bool \u2013 True if started, False if already running. Source code in python/neuro_rpc/RPCTracker.py def start_monitoring(self, timeout_callback=None): \"\"\" Start the background monitoring thread. Args: timeout_callback (Callable, optional): Callback called with a list of timed-out requests. Returns: bool: True if started, False if already running. \"\"\" if self._monitor_thread is not None and self._monitor_thread.is_alive(): if self.logger: self.logger.warning(\"Monitoring thread already running\") return False self.timeout_callback = timeout_callback self._should_stop.clear() self._monitor_thread = threading.Thread( target=self._monitor_loop, name=\"RPCTracker-Monitor\", daemon=True ) self._monitor_thread.start() if self.logger: self.logger.debug(\"Message tracking monitor started\") return True","title":"start_monitoring"},{"location":"reference/RPCTracker/#neuro_rpc.RPCTracker.RPCTracker.stop_monitoring","text":"Stop the background monitoring thread. Returns: bool \u2013 True if stopped cleanly, False otherwise. Source code in python/neuro_rpc/RPCTracker.py def stop_monitoring(self): \"\"\" Stop the background monitoring thread. Returns: bool: True if stopped cleanly, False otherwise. \"\"\" if self._monitor_thread is None or not self._monitor_thread.is_alive(): return False self._should_stop.set() self._monitor_thread.join(timeout=5.0) if self._monitor_thread.is_alive(): if self.logger: self.logger.warning(\"Monitoring thread did not shut down cleanly\") return False else: if self.logger: self.logger.debug(\"Message tracking monitor stopped\") return True","title":"stop_monitoring"},{"location":"reference/RPCTracker/#neuro_rpc.RPCTracker.RPCTracker.track_incoming_request","text":"Track an incoming request from server. Parameters: request ( RPCRequest ) \u2013 Request object received. Source code in python/neuro_rpc/RPCTracker.py def track_incoming_request(self, request: RPCRequest): \"\"\" Track an incoming request from server. Args: request (RPCRequest): Request object received. \"\"\" with self._tracking_lock: self.logger.debug(f\"Tracking incoming request: {request}\") self.incoming_requests[request.id] = (time.time(), request.method) self.stats[\"incoming_requests_count\"] += 1","title":"track_incoming_request"},{"location":"reference/RPCTracker/#neuro_rpc.RPCTracker.RPCTracker.track_incoming_response","text":"Track an incoming response from server. Parameters: response ( RPCResponse ) \u2013 Response object received. Source code in python/neuro_rpc/RPCTracker.py def track_incoming_response(self, response: RPCResponse): \"\"\" Track an incoming response from server. Args: response (RPCResponse): Response object received. \"\"\" with self._tracking_lock: if response.id in self.outgoing_requests: del self.outgoing_requests[response.id] self.stats[\"incoming_responses_count\"] += 1 else: if self.logger: self.logger.warning(f\"Received response for unknown request ID: {response.id}\")","title":"track_incoming_response"},{"location":"reference/RPCTracker/#neuro_rpc.RPCTracker.RPCTracker.track_outgoing_request","text":"Track an outgoing request. Parameters: request ( RPCRequest ) \u2013 Request object being sent. timeout ( int , default: 60 ) \u2013 Timeout in seconds for this request. Source code in python/neuro_rpc/RPCTracker.py def track_outgoing_request(self, request: RPCRequest, timeout=60): \"\"\" Track an outgoing request. Args: request (RPCRequest): Request object being sent. timeout (int): Timeout in seconds for this request. \"\"\" with self._tracking_lock: self.outgoing_requests[request.id] = (time.time(), request.method, timeout) self.stats[\"outgoing_requests_count\"] += 1","title":"track_outgoing_request"},{"location":"reference/RPCTracker/#neuro_rpc.RPCTracker.RPCTracker.track_outgoing_response","text":"Track an outgoing response. Parameters: response ( RPCResponse ) \u2013 Response object being sent. Source code in python/neuro_rpc/RPCTracker.py def track_outgoing_response(self, response: RPCResponse): \"\"\" Track an outgoing response. Args: response (RPCResponse): Response object being sent. \"\"\" with self._tracking_lock: self.logger.debug(f\"Tracking outgoing response: {response.id}, {response.is_success}\") if response.id in self.incoming_requests: del self.incoming_requests[response.id] self.outgoing_responses[response.id] = (time.time(), response.is_success) self.stats[\"outgoing_responses_count\"] += 1","title":"track_outgoing_response"}]}